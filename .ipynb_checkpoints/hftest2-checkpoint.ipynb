{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.inception_v3 import InceptionV3,preprocess_input,decode_predictions\n",
    "from keras.preprocessing import image\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf\n"
     ]
    }
   ],
   "source": [
    "# a bemenő képek mérete (Inception V3 bemenete 299x299)\n",
    "img_height=299\n",
    "img_width=299\n",
    "\n",
    "# a tanító és validációs adatbázis elérési útvonala, teszt adatbázis most nincs\n",
    "train_data_dir = 'data/train'\n",
    "validation_data_dir = 'data/validation'\n",
    "# a tanító és validációs adatok száma\n",
    "nb_train_samples = 1111\n",
    "nb_validation_samples = 1000\n",
    "# epoch szám\n",
    "nb_epoch=50\n",
    "\n",
    "# előtanított modell betöltése, a fully-connected rétegek nélkül\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "# az utolsó konvolúciós réteg utána egy global average pooling réteget teszünk, ez rögtön \"lapítja\" (flatten) a 2D konvolúciót\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# ezután hozzáadunk egy előrecsatolt réteget ReLU aktivációs függvénnyel\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "# és végül egy kimenete lesz a hálónak - a \"binary_crossentropy\" költségfüggvénynek erre van szüksége\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "# a model létrehozása\n",
    "model = Model(input=base_model.input, output=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# két lépésben fogjuk tanítani a hálót\n",
    "# az első lépésben csak az előrecsatolt rétegeket tanítjuk, a konvolúciós rétegeket befagyasztjuk\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "# lefordítjuk a modelt (fontos, hogy ezt a rétegek befagyasztása után csináljuk\"\n",
    "# mivel két osztályunk van, ezért bináris keresztentrópia költségfüggvényt használunk\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[194 138  64]\n",
      "  [203 147  73]\n",
      "  [210 154  80]\n",
      "  ..., \n",
      "  [ 93  40   0]\n",
      "  [101  48   8]\n",
      "  [104  51  11]]\n",
      "\n",
      " [[204 148  74]\n",
      "  [209 153  79]\n",
      "  [209 153  79]\n",
      "  ..., \n",
      "  [188 136  89]\n",
      "  [176 123  79]\n",
      "  [167 114  70]]\n",
      "\n",
      " [[211 155  81]\n",
      "  [213 157  83]\n",
      "  [212 156  82]\n",
      "  ..., \n",
      "  [224 173 120]\n",
      "  [221 169 119]\n",
      "  [218 166 116]]\n",
      "\n",
      " ..., \n",
      " [[102  84  48]\n",
      "  [103  85  49]\n",
      "  [100  82  46]\n",
      "  ..., \n",
      "  [ 80  74  52]\n",
      "  [ 73  67  45]\n",
      "  [ 76  70  48]]\n",
      "\n",
      " [[ 90  79  51]\n",
      "  [ 92  81  51]\n",
      "  [ 92  78  49]\n",
      "  ..., \n",
      "  [ 89  81  60]\n",
      "  [ 73  62  42]\n",
      "  [ 90  82  61]]\n",
      "\n",
      " [[ 83  73  46]\n",
      "  [ 85  75  48]\n",
      "  [ 84  73  45]\n",
      "  ..., \n",
      "  [ 91  80  60]\n",
      "  [ 71  60  40]\n",
      "  [ 90  79  59]]]\n",
      "[[[251 233 213]\n",
      "  [251 233 213]\n",
      "  [251 233 213]\n",
      "  ..., \n",
      "  [250 235 212]\n",
      "  [250 235 212]\n",
      "  [250 235 212]]\n",
      "\n",
      " [[251 233 213]\n",
      "  [251 233 213]\n",
      "  [251 233 213]\n",
      "  ..., \n",
      "  [250 235 212]\n",
      "  [250 235 212]\n",
      "  [250 235 212]]\n",
      "\n",
      " [[250 233 213]\n",
      "  [250 233 213]\n",
      "  [250 233 213]\n",
      "  ..., \n",
      "  [250 235 212]\n",
      "  [250 235 212]\n",
      "  [250 235 212]]\n",
      "\n",
      " ..., \n",
      " [[251 236 217]\n",
      "  [251 236 217]\n",
      "  [251 236 217]\n",
      "  ..., \n",
      "  [248 237 219]\n",
      "  [248 237 219]\n",
      "  [248 237 219]]\n",
      "\n",
      " [[248 233 214]\n",
      "  [249 234 215]\n",
      "  [250 235 216]\n",
      "  ..., \n",
      "  [249 238 220]\n",
      "  [249 238 220]\n",
      "  [249 238 220]]\n",
      "\n",
      " [[248 233 214]\n",
      "  [249 234 215]\n",
      "  [250 235 216]\n",
      "  ..., \n",
      "  [249 238 220]\n",
      "  [249 238 220]\n",
      "  [249 238 220]]]\n",
      "[[[31 26  6]\n",
      "  [57 52 32]\n",
      "  [55 50 30]\n",
      "  ..., \n",
      "  [50 44 44]\n",
      "  [50 44 46]\n",
      "  [47 41 43]]\n",
      "\n",
      " [[37 32 12]\n",
      "  [48 43 23]\n",
      "  [57 52 32]\n",
      "  ..., \n",
      "  [41 35 35]\n",
      "  [41 35 37]\n",
      "  [40 34 36]]\n",
      "\n",
      " [[93 88 69]\n",
      "  [56 51 32]\n",
      "  [45 40 21]\n",
      "  ..., \n",
      "  [40 36 35]\n",
      "  [37 33 34]\n",
      "  [30 26 27]]\n",
      "\n",
      " ..., \n",
      " [[38 39 33]\n",
      "  [23 24 18]\n",
      "  [21 22 16]\n",
      "  ..., \n",
      "  [23 20 15]\n",
      "  [30 27 22]\n",
      "  [44 41 36]]\n",
      "\n",
      " [[28 29 24]\n",
      "  [21 22 17]\n",
      "  [35 36 31]\n",
      "  ..., \n",
      "  [92 82 80]\n",
      "  [37 26 24]\n",
      "  [32 21 17]]\n",
      "\n",
      " [[32 33 28]\n",
      "  [23 24 19]\n",
      "  [34 35 30]\n",
      "  ..., \n",
      "  [46 28 28]\n",
      "  [39 21 19]\n",
      "  [72 54 52]]]\n",
      "[[[ 33  32  28]\n",
      "  [ 21  20  16]\n",
      "  [ 19  15  14]\n",
      "  ..., \n",
      "  [184  74  37]\n",
      "  [213  78  31]\n",
      "  [213  67  16]]\n",
      "\n",
      " [[ 38  37  33]\n",
      "  [ 31  30  26]\n",
      "  [ 33  29  28]\n",
      "  ..., \n",
      "  [206  96  63]\n",
      "  [231  97  59]\n",
      "  [209  64  19]]\n",
      "\n",
      " [[ 29  25  22]\n",
      "  [ 27  23  20]\n",
      "  [ 33  29  28]\n",
      "  ..., \n",
      "  [169  58  38]\n",
      "  [187  53  26]\n",
      "  [255 133 102]]\n",
      "\n",
      " ..., \n",
      " [[ 74  65  50]\n",
      "  [ 57  51  39]\n",
      "  [ 77  78  72]\n",
      "  ..., \n",
      "  [ 26  20  20]\n",
      "  [ 59  53  53]\n",
      "  [ 96  90  90]]\n",
      "\n",
      " [[ 71  59  43]\n",
      "  [ 85  79  67]\n",
      "  [ 59  60  55]\n",
      "  ..., \n",
      "  [ 38  32  32]\n",
      "  [ 92  86  86]\n",
      "  [ 96  90  90]]\n",
      "\n",
      " [[ 82  70  54]\n",
      "  [105  99  87]\n",
      "  [ 83  85  82]\n",
      "  ..., \n",
      "  [ 42  36  36]\n",
      "  [ 77  71  71]\n",
      "  [103  97  97]]]\n",
      "[[[125 135  72]\n",
      "  [145 155  92]\n",
      "  [198 208 148]\n",
      "  ..., \n",
      "  [149 155  93]\n",
      "  [154 160  96]\n",
      "  [197 204 137]]\n",
      "\n",
      " [[191 201 141]\n",
      "  [208 218 158]\n",
      "  [188 197 140]\n",
      "  ..., \n",
      "  [152 158  98]\n",
      "  [149 155  91]\n",
      "  [175 182 115]]\n",
      "\n",
      " [[211 221 168]\n",
      "  [190 200 148]\n",
      "  [217 227 177]\n",
      "  ..., \n",
      "  [163 168 110]\n",
      "  [153 159  97]\n",
      "  [157 163  99]]\n",
      "\n",
      " ..., \n",
      " [[199 208 165]\n",
      "  [204 213 170]\n",
      "  [188 196 155]\n",
      "  ..., \n",
      "  [192 186 110]\n",
      "  [212 206 130]\n",
      "  [209 203 127]]\n",
      "\n",
      " [[233 231 174]\n",
      "  [230 229 173]\n",
      "  [211 210 154]\n",
      "  ..., \n",
      "  [181 175  97]\n",
      "  [137 134  57]\n",
      "  [189 186 109]]\n",
      "\n",
      " [[211 203 141]\n",
      "  [216 210 148]\n",
      "  [200 194 134]\n",
      "  ..., \n",
      "  [106 100  22]\n",
      "  [165 162  85]\n",
      "  [143 141  64]]]\n",
      "[[[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ..., \n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ..., \n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ..., \n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " ..., \n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ..., \n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ..., \n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ..., \n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]]\n",
      "[[[134 132  94]\n",
      "  [134 129  91]\n",
      "  [176 158 118]\n",
      "  ..., \n",
      "  [ 50  70  61]\n",
      "  [ 44  67  57]\n",
      "  [ 44  72  60]]\n",
      "\n",
      " [[130 125  87]\n",
      "  [126 117  76]\n",
      "  [192 173 131]\n",
      "  ..., \n",
      "  [ 41  58  50]\n",
      "  [ 36  59  49]\n",
      "  [ 36  64  52]]\n",
      "\n",
      " [[119 107  65]\n",
      "  [154 140  95]\n",
      "  [195 173 126]\n",
      "  ..., \n",
      "  [ 47  62  55]\n",
      "  [ 43  64  55]\n",
      "  [ 41  67  56]]\n",
      "\n",
      " ..., \n",
      " [[185 137  89]\n",
      "  [146  98  50]\n",
      "  [147 101  52]\n",
      "  ..., \n",
      "  [190 173 127]\n",
      "  [138 123  80]\n",
      "  [ 87  75  33]]\n",
      "\n",
      " [[161 116  77]\n",
      "  [167 122  83]\n",
      "  [158 115  73]\n",
      "  ..., \n",
      "  [235 208 163]\n",
      "  [210 187 145]\n",
      "  [ 72  51   8]]\n",
      "\n",
      " [[148 103  64]\n",
      "  [155 110  71]\n",
      "  [144 101  59]\n",
      "  ..., \n",
      "  [186 159 114]\n",
      "  [119  96  54]\n",
      "  [144 123  80]]]\n",
      "[[[255 239 182]\n",
      "  [250 224 167]\n",
      "  [254 223 166]\n",
      "  ..., \n",
      "  [246 222 158]\n",
      "  [249 224 160]\n",
      "  [245 220 156]]\n",
      "\n",
      " [[245 219 162]\n",
      "  [245 216 158]\n",
      "  [254 223 166]\n",
      "  ..., \n",
      "  [241 217 153]\n",
      "  [245 220 156]\n",
      "  [242 217 153]]\n",
      "\n",
      " [[247 216 159]\n",
      "  [247 217 157]\n",
      "  [239 207 148]\n",
      "  ..., \n",
      "  [247 223 159]\n",
      "  [252 227 163]\n",
      "  [253 228 164]]\n",
      "\n",
      " ..., \n",
      " [[196 151 110]\n",
      "  [202 157 116]\n",
      "  [203 159 120]\n",
      "  ..., \n",
      "  [235 193 145]\n",
      "  [236 194 146]\n",
      "  [232 190 142]]\n",
      "\n",
      " [[219 176 133]\n",
      "  [209 166 123]\n",
      "  [194 151 109]\n",
      "  ..., \n",
      "  [232 190 142]\n",
      "  [227 185 137]\n",
      "  [218 176 128]]\n",
      "\n",
      " [[206 163 121]\n",
      "  [204 161 119]\n",
      "  [215 171 132]\n",
      "  ..., \n",
      "  [220 178 130]\n",
      "  [226 184 136]\n",
      "  [225 183 135]]]\n",
      "[[[50 49 29]\n",
      "  [58 57 37]\n",
      "  [58 57 37]\n",
      "  ..., \n",
      "  [19 15 12]\n",
      "  [20 14 16]\n",
      "  [48 42 44]]\n",
      "\n",
      " [[45 44 26]\n",
      "  [53 52 32]\n",
      "  [88 87 69]\n",
      "  ..., \n",
      "  [17 13 12]\n",
      "  [21 15 17]\n",
      "  [39 33 35]]\n",
      "\n",
      " [[52 50 35]\n",
      "  [38 37 19]\n",
      "  [78 76 61]\n",
      "  ..., \n",
      "  [ 6  2  1]\n",
      "  [ 8  4  5]\n",
      "  [10  5  9]]\n",
      "\n",
      " ..., \n",
      " [[48 32 17]\n",
      "  [59 43 28]\n",
      "  [74 58 45]\n",
      "  ..., \n",
      "  [ 9  8 13]\n",
      "  [13  8 12]\n",
      "  [14 10 11]]\n",
      "\n",
      " [[75 58 48]\n",
      "  [21  7  0]\n",
      "  [55 41 32]\n",
      "  ..., \n",
      "  [ 9  7 10]\n",
      "  [19 15 16]\n",
      "  [ 8  4  3]]\n",
      "\n",
      " [[35 21 12]\n",
      "  [47 33 24]\n",
      "  [42 27 20]\n",
      "  ..., \n",
      "  [19 18 16]\n",
      "  [38 34 33]\n",
      "  [13  9  6]]]\n",
      "[[[220 208 168]\n",
      "  [220 208 168]\n",
      "  [219 207 167]\n",
      "  ..., \n",
      "  [123 112  66]\n",
      "  [108  97  52]\n",
      "  [ 95  84  39]]\n",
      "\n",
      " [[222 210 170]\n",
      "  [222 210 170]\n",
      "  [221 209 169]\n",
      "  ..., \n",
      "  [117 106  60]\n",
      "  [101  90  45]\n",
      "  [ 88  77  32]]\n",
      "\n",
      " [[225 213 173]\n",
      "  [224 212 172]\n",
      "  [224 212 172]\n",
      "  ..., \n",
      "  [119 108  63]\n",
      "  [106  94  52]\n",
      "  [ 96  84  42]]\n",
      "\n",
      " ..., \n",
      " [[146 143  98]\n",
      "  [147 144  99]\n",
      "  [149 146 101]\n",
      "  ..., \n",
      "  [  3   5   2]\n",
      "  [  4   6   3]\n",
      "  [  5   7   4]]\n",
      "\n",
      " [[141 138  95]\n",
      "  [143 140  97]\n",
      "  [145 142  99]\n",
      "  ..., \n",
      "  [  3   5   2]\n",
      "  [  4   6   3]\n",
      "  [  5   7   4]]\n",
      "\n",
      " [[149 145 107]\n",
      "  [149 145 107]\n",
      "  [149 145 107]\n",
      "  ..., \n",
      "  [  4   6   3]\n",
      "  [  5   7   4]\n",
      "  [  6   8   5]]]\n",
      "[[[214 180 153]\n",
      "  [224 190 163]\n",
      "  [224 190 163]\n",
      "  ..., \n",
      "  [114  77  68]\n",
      "  [186 159 142]\n",
      "  [101  72  56]]\n",
      "\n",
      " [[213 179 152]\n",
      "  [222 188 161]\n",
      "  [223 189 162]\n",
      "  ..., \n",
      "  [130  98  87]\n",
      "  [174 148 131]\n",
      "  [105  77  63]]\n",
      "\n",
      " [[209 178 150]\n",
      "  [219 188 160]\n",
      "  [220 189 161]\n",
      "  ..., \n",
      "  [156 129 118]\n",
      "  [163 142 125]\n",
      "  [125 102  88]]\n",
      "\n",
      " ..., \n",
      " [[111  98  66]\n",
      "  [100  89  57]\n",
      "  [ 93  82  50]\n",
      "  ..., \n",
      "  [160 137 106]\n",
      "  [153 132 101]\n",
      "  [145 124  93]]\n",
      "\n",
      " [[ 96  81  52]\n",
      "  [ 95  81  52]\n",
      "  [ 95  81  54]\n",
      "  ..., \n",
      "  [152 128 100]\n",
      "  [146 125  96]\n",
      "  [139 118  89]]\n",
      "\n",
      " [[ 85  69  43]\n",
      "  [ 94  78  52]\n",
      "  [100  86  60]\n",
      "  ..., \n",
      "  [141 117  89]\n",
      "  [138 117  90]\n",
      "  [137 116  89]]]\n",
      "[[[ 97  73  39]\n",
      "  [ 96  75  44]\n",
      "  [ 96  81  58]\n",
      "  ..., \n",
      "  [ 66  71  65]\n",
      "  [ 55  60  54]\n",
      "  [ 57  62  56]]\n",
      "\n",
      " [[166 142 108]\n",
      "  [ 84  63  32]\n",
      "  [120 105  82]\n",
      "  ..., \n",
      "  [ 61  66  60]\n",
      "  [ 52  57  51]\n",
      "  [ 58  63  57]]\n",
      "\n",
      " [[196 172 138]\n",
      "  [112  91  60]\n",
      "  [110  95  72]\n",
      "  ..., \n",
      "  [ 57  62  56]\n",
      "  [ 52  57  51]\n",
      "  [ 61  66  60]]\n",
      "\n",
      " ..., \n",
      " [[137 114  80]\n",
      "  [149 126  92]\n",
      "  [141 118  84]\n",
      "  ..., \n",
      "  [240 199 143]\n",
      "  [239 200 143]\n",
      "  [232 196 138]]\n",
      "\n",
      " [[163 143 108]\n",
      "  [177 157 122]\n",
      "  [173 153 118]\n",
      "  ..., \n",
      "  [237 191 139]\n",
      "  [233 190 139]\n",
      "  [236 195 141]]\n",
      "\n",
      " [[151 131  96]\n",
      "  [160 140 105]\n",
      "  [153 133  98]\n",
      "  ..., \n",
      "  [236 188 139]\n",
      "  [234 188 138]\n",
      "  [238 195 144]]]\n",
      "[[[ 95  80  83]\n",
      "  [ 73  58  61]\n",
      "  [ 76  61  64]\n",
      "  ..., \n",
      "  [243 234 237]\n",
      "  [240 231 234]\n",
      "  [241 232 235]]\n",
      "\n",
      " [[ 53  38  41]\n",
      "  [ 79  64  67]\n",
      "  [ 93  78  81]\n",
      "  ..., \n",
      "  [ 32  23  26]\n",
      "  [ 32  23  26]\n",
      "  [ 49  40  43]]\n",
      "\n",
      " [[ 85  73  75]\n",
      "  [ 70  58  60]\n",
      "  [ 73  61  63]\n",
      "  ..., \n",
      "  [ 49  40  43]\n",
      "  [ 56  47  50]\n",
      "  [ 65  56  59]]\n",
      "\n",
      " ..., \n",
      " [[219 204 211]\n",
      "  [ 46  31  38]\n",
      "  [ 67  54  61]\n",
      "  ..., \n",
      "  [ 38  38  40]\n",
      "  [ 38  38  40]\n",
      "  [ 50  50  52]]\n",
      "\n",
      " [[156 141 148]\n",
      "  [ 81  66  73]\n",
      "  [ 84  71  78]\n",
      "  ..., \n",
      "  [ 35  35  37]\n",
      "  [ 36  36  38]\n",
      "  [ 48  48  50]]\n",
      "\n",
      " [[165 150 157]\n",
      "  [ 87  72  79]\n",
      "  [ 68  55  62]\n",
      "  ..., \n",
      "  [ 27  27  29]\n",
      "  [ 32  32  34]\n",
      "  [ 49  49  51]]]\n",
      "[[[189 180 165]\n",
      "  [181 172 157]\n",
      "  [189 180 165]\n",
      "  ..., \n",
      "  [181 176 154]\n",
      "  [164 159 137]\n",
      "  [205 200 178]]\n",
      "\n",
      " [[197 188 173]\n",
      "  [191 182 167]\n",
      "  [189 180 165]\n",
      "  ..., \n",
      "  [180 175 153]\n",
      "  [184 179 159]\n",
      "  [217 212 190]]\n",
      "\n",
      " [[197 188 173]\n",
      "  [198 189 174]\n",
      "  [190 181 166]\n",
      "  ..., \n",
      "  [179 174 154]\n",
      "  [198 193 174]\n",
      "  [207 202 182]]\n",
      "\n",
      " ..., \n",
      " [[ 94  18  22]\n",
      "  [ 91  19  22]\n",
      "  [ 74  13  10]\n",
      "  ..., \n",
      "  [  3  18  11]\n",
      "  [  3  18  13]\n",
      "  [  5  20  15]]\n",
      "\n",
      " [[105  29  33]\n",
      "  [ 96  24  27]\n",
      "  [ 69   8   5]\n",
      "  ..., \n",
      "  [  7  20  11]\n",
      "  [ 10  23  16]\n",
      "  [ 14  27  20]]\n",
      "\n",
      " [[112  36  40]\n",
      "  [101  29  32]\n",
      "  [ 75  14  11]\n",
      "  ..., \n",
      "  [ 21  34  25]\n",
      "  [ 21  34  27]\n",
      "  [ 21  34  27]]]\n",
      "\n",
      "['69999.jpg', 'f44205b1eb2de981de766e0688f8cbac', 'Portrait of Balieva', 'Expressionism', 'portrait', '1925']\n",
      "['79999.jpg', 'da9ab2081b197129eeb91477d239be00', 'With an effort he looked at them as they passed', 'Neo-Romanticism', 'illustration', '']\n",
      "['99997.jpg', '3cc9a44380296d93e68b71a27643c25f', 'Portrait of Achille Emperaire', 'Romanticism', 'portrait', '1868']\n",
      "['99995.jpg', '8e441c5899bf3d2f3b2c493e62fb92bf', 'Urawa', 'Ukiyo-e', 'portrait', '']\n",
      "['99996.jpg', 'c56bcab4b317984013ebef5d3c4b5906', 'Gloucester Boats', 'Impressionism', 'marina', '1902']\n",
      "['29999.jpg', 'cc47068929413a16aa707faefbdf4b70', 'Ganna Walska in Manon 02', 'Art Deco', 'design', '']\n",
      "['89999.jpg', 'd500fe452aef7a6f90de16197a9670bf', 'Garden of Italy', 'Impressionism', 'landscape', '']\n",
      "['99999.jpg', 'e1587900e782de448f604b37cde0fdfd', 'Rosa Porprina', 'Expressionism', 'portrait', '1915']\n",
      "['99990.jpg', '3f93b217bd0dbf874f973958f1eb6df4', 'Mother Holding Her Child in a Doorway', 'Baroque', 'genre painting', '1667']\n",
      "['39999.jpg', '69904cf890070e9593a566394d5dece4', 'Miss Close  ', 'Expressionism', 'portrait', '1939']\n",
      "['99998.jpg', 'f0a20221a0109091e49d14c761574cd8', 'Lumberville', 'Impressionism', 'landscape', '']\n",
      "['99992.jpg', 'f14a3a6cc3112c9e92bc6c33c88eb264', 'From An Absent One', 'Romanticism', 'genre painting', '1871']\n",
      "['9999.jpg', '485d901dc4df30b128bf01cb6e229767', 'Untitled', 'Sōsaku hanga', 'cityscape', '1967']\n",
      "['19999.jpg', '5b6a7be5ffc6a27b91bd3210ffa2e088', 'Three Self-Portraits with a White Wall  ', 'Expressionism', 'self-portrait', '1957']\n",
      "Hello\n"
     ]
    }
   ],
   "source": [
    "#import sys\n",
    "#sys.path.append('/home/bence/Documents/vitmav45-2016-train-validate-test-repeat-master/data preparation')\n",
    "#import preprocess as ppx\n",
    "\n",
    "image_file_names, data = ppx.csv_load()\n",
    "image_name_dict, images = ppx.load_images(image_file_names)\n",
    "train_images, train_data = ppx.data_preprocess(images, data, image_name_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.array([np.asarray(ls[1]) for ls in train_images])\n",
    "labels = np.array([ls[1] for ls in train_data])\n",
    "labels = np.arange(14)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# kép felkészítése a betöltésre és adatdúsításra\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow(arr, labels, batch_size=1)\n",
    "validation_generator = test_datagen.flow(arr, labels, batch_size=1)\n",
    "#train_generator = train_datagen.flow_from_directory(train_data_dir, target_size=(img_height, img_width), batch_size=32, class_mode='binary')\n",
    "#validation_generator = test_datagen.flow_from_directory(validation_data_dir, target_size=(img_height, img_width), batch_size=32, class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.4/threading.py\", line 920, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.4/threading.py\", line 868, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.4/dist-packages/keras/engine/training.py\", line 425, in data_generator_task\n",
      "    generator_output = next(generator)\n",
      "  File \"/usr/local/lib/python3.4/dist-packages/keras/preprocessing/image.py\", line 458, in __next__\n",
      "    return self.next(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.4/dist-packages/keras/preprocessing/image.py\", line 493, in next\n",
      "    x = self.image_data_generator.random_transform(x.astype('float32'))\n",
      "  File \"/usr/local/lib/python3.4/dist-packages/keras/preprocessing/image.py\", line 362, in random_transform\n",
      "    fill_mode=self.fill_mode, cval=self.cval)\n",
      "  File \"/usr/local/lib/python3.4/dist-packages/keras/preprocessing/image.py\", line 104, in apply_transform\n",
      "    x = np.rollaxis(x, channel_index, 0)\n",
      "  File \"/usr/local/lib/python3.4/dist-packages/numpy/core/numeric.py\", line 1450, in rollaxis\n",
      "    raise ValueError(msg % ('axis', axis, n))\n",
      "ValueError: rollaxis: axis (2) must be >=0 and < 2\n",
      "\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "output of generator should be a tuple (x, y, sample_weight) or (x, y). Found: None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-32fabdaa6afa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# ez a függvény egyszerre végzi az adatdúsítást és a háló tanítását\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_train_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# most már van egy célra betanított osztályozónk, ami az Inception V3 előtanított hálót követi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# most jön a második lépés, aminek a során a konvolúciós háló mélyebb rétegeit fagyasztjuk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe)\u001b[0m\n\u001b[1;32m   1415\u001b[0m                     raise Exception('output of generator should be a tuple '\n\u001b[1;32m   1416\u001b[0m                                     \u001b[0;34m'(x, y, sample_weight) '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1417\u001b[0;31m                                     'or (x, y). Found: ' + str(generator_output))\n\u001b[0m\u001b[1;32m   1418\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1419\u001b[0m                     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: output of generator should be a tuple (x, y, sample_weight) or (x, y). Found: None"
     ]
    }
   ],
   "source": [
    "# két lépésben fogjuk tanítani a hálót\n",
    "# az első lépésben csak az előrecsatolt rétegeket tanítjuk, a konvolúciós rétegeket befagyasztjuk\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "# lefordítjuk a modelt (fontos, hogy ezt a rétegek befagyasztása után csináljuk\"\n",
    "# mivel két osztályunk van, ezért bináris keresztentrópia költségfüggvényt használunk\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "# kép felkészítése a betöltésre és adatdúsításra\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(train_data_dir, target_size=(img_height, img_width), batch_size=32, class_mode='binary')\n",
    "validation_generator = test_datagen.flow_from_directory(validation_data_dir, target_size=(img_height, img_width), batch_size=32, class_mode='binary')\n",
    "\n",
    "# ez a függvény egyszerre végzi az adatdúsítást és a háló tanítását\n",
    "model.fit_generator(train_generator, samples_per_epoch=nb_train_samples, nb_epoch=nb_epoch, validation_data=validation_generator, nb_val_samples=nb_validation_samples)\n",
    "\n",
    "# most már van egy célra betanított osztályozónk, ami az Inception V3 előtanított hálót követi\n",
    "# most jön a második lépés, aminek a során a konvolúciós háló mélyebb rétegeit fagyasztjuk\n",
    "# felsőbb rétegeit pedig tovább tanítjuk\n",
    "\n",
    "# ehhez először nézzük meg a háló felépítését\n",
    "print(\"Az Inception V3 konvolúciós rétegei:\")\n",
    "for i, layer in enumerate(base_model.layers):\n",
    "   print(i, layer.name)\n",
    "\n",
    "# majd a hálónak csak az első 172 rétegét fagyasztjuk, a többit pedig engedjük tanulni\n",
    "for layer in model.layers[:172]:\n",
    "   layer.trainable = False\n",
    "for layer in model.layers[172:]:\n",
    "   layer.trainable = True\n",
    "\n",
    "# ez után újra le kell fordítanunk a hálót, hogy most már az Inception V3 felsőbb rétegei tanuljanak\n",
    "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='binary_crossentropy')\n",
    "\n",
    "# és ismét indítunk egy tanítást, ezúttal nem csak az előrecsatolt rétegek,\n",
    "# hanem az Inception V3 felső rétegei is tovább tanulnak\n",
    "model.fit_generator(train_generator, samples_per_epoch=nb_train_samples, nb_epoch=nb_epoch, validation_data=validation_generator, nb_val_samples=nb_validation_samples)\n",
    "\n",
    "print(\"Tanítás vége.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.inception_v3 import InceptionV3,preprocess_input,decode_predictions\n",
    "from keras.preprocessing import image\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Input, Dense, GlobalAveragePooling2D, merge, Dropout, Convolution2D, Lambda\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "from keras.callbacks import Callback\n",
    "from sklearn import preprocessing\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('358474690052f63f9107c823b7a61686', 165),\n",
       " ('342d7068656b00878b23e1031a3ddf50', 165),\n",
       " ('db85b84c1c01fa143b9294f00f7acbeb', 167),\n",
       " ('30134467c49a3350f74b4311506f8386', 171),\n",
       " ('795985c5c0e7c704a354a487bdffeef5', 171),\n",
       " ('ed9cf03b71a8a71d41ecb4e8406a0877', 172),\n",
       " ('a087f33967e659c63924aa07c89b948f', 172),\n",
       " ('3a320926ef941d53716127548523450c', 172),\n",
       " ('24ed88087b0ffeb763e89a197a5cde0d', 172),\n",
       " ('a7b6670e2d23f415998849a8fdedae18', 174),\n",
       " ('8b1800319323ab9b0ce2e0b11b3f4772', 175),\n",
       " ('79f6b47483600c140c91e901f746a368', 176),\n",
       " ('3b4ee6d6140803ebef405983f23ffcc1', 176),\n",
       " ('56221362cba30b7e0c96111cc38c5fcd', 176),\n",
       " ('83518d02afc5754dd9e79985f56c3355', 178),\n",
       " ('9c948f31fc16aca442cc91e7fe05fb95', 179),\n",
       " ('b31c8ec49c09506f17ec3c0c04fce567', 179),\n",
       " ('062244b785e58518f2f189329633c59e', 181),\n",
       " ('63e73f693e541f53d98ed6c93d03ef40', 185),\n",
       " ('39c465a1d078121873a31807ce9dc2ed', 185),\n",
       " ('ea2beb11e25ec317263983dbdd6de81e', 186),\n",
       " ('1d6d112c140cb6d1d763a7ca73f2eec0', 187),\n",
       " ('74a1dad53214d04514269a188f16683a', 187),\n",
       " ('2cd87bc71a43270dc7ce0917f6f6d980', 188),\n",
       " ('7b5a9186df853ff921c211145ca5ab59', 189),\n",
       " ('489c7bf979f6a993869fdc0ae7e4ae34', 192),\n",
       " ('dcb1d130c7640aefc60890d0e90d472d', 195),\n",
       " ('ede635e53e1b4a905bbea74de30371cf', 195),\n",
       " ('fbaf536ad899a31e80be9ff101b119cc', 197),\n",
       " ('861c29e13205420326f7443ea77de5c9', 200),\n",
       " ('c56bcab4b317984013ebef5d3c4b5906', 200),\n",
       " ('de42ef05d5901837bbe974fdb3c30ba5', 202),\n",
       " ('4b0465826ffd6db797ea6f3a5898df79', 205),\n",
       " ('82665201c4108381d854740ddcb86e67', 205),\n",
       " ('1e8267251976e6f3b771b00f32c5798b', 206),\n",
       " ('bfb541e54ad5c7320e8f80e2a2163e93', 206),\n",
       " ('aceaa52f487dd19129857232b2eeb3d5', 212),\n",
       " ('5e560e9b2ae0c20cfc57b308742bc677', 213),\n",
       " ('b64b426fa2b080ad94a2e1c7f423413c', 214),\n",
       " ('5ae394770a82dac7cea5d95ef6482a11', 214),\n",
       " ('45f4183820ce1fa775f8a27d3120aad6', 215),\n",
       " ('bc58ed3c3e7750f9644953020a39e867', 220),\n",
       " ('ccb8b07e7e3d837b2cd08d3edaf009cd', 220),\n",
       " ('4a30943bf6dd5da55d12ccd14aaff0d8', 229),\n",
       " ('68cbc428edbcf480cbbb9a0e66e7046d', 232),\n",
       " ('9649a0013a798a8367d2c493e37468ec', 245),\n",
       " ('7b016984b86b58f83977299591cf4e38', 246),\n",
       " ('e1587900e782de448f604b37cde0fdfd', 256),\n",
       " ('147b0f64f4c2848bc0ad7bc1cdf74afe', 258),\n",
       " ('1468ab18764365ded902fc726aec2c89', 258),\n",
       " ('129349585c3d1f312535b6619fc36bf7', 267),\n",
       " ('c9380d13360b37f21cfd174d92a7247e', 268),\n",
       " ('8e441c5899bf3d2f3b2c493e62fb92bf', 268),\n",
       " ('c8041306a183cbaf39ff8cd707c9cc7f', 278),\n",
       " ('6460e3ba02dfa3b57ebf5d3d0823aa47', 286),\n",
       " ('3937af6d364e2f24d1cce16fe3916536', 291),\n",
       " ('dc589f213ba7bd398714ac2796b7c0ab', 291),\n",
       " ('62b4406512c45730d2c7c40f5e3d0d12', 294),\n",
       " ('31dbc08b8d0a3196c5484c0c068b2bcc', 294),\n",
       " ('3edc6a404b8c67b7dad1405d52228c96', 297),\n",
       " ('49bb8d79587c2172c6cd04dd705fd891', 297),\n",
       " ('8cdd41002b7b5c5d112865054a7fe13e', 298),\n",
       " ('cc47068929413a16aa707faefbdf4b70', 304),\n",
       " ('54e7b38b5c91716bd3ad99a0ab740a18', 304),\n",
       " ('bd14ef3c1a25cf0c5368ccd92a3c5f04', 304),\n",
       " ('e60882af79cababb03ddfa980a75448c', 305),\n",
       " ('c31b03be3da5810b44ea4782d2f3b8a0', 320),\n",
       " ('512fb34e01bd21a92e7ec1380577c985', 321),\n",
       " ('b36edf57ed623e40e433565053f5f6ca', 345),\n",
       " ('234c8d1df0b49b512791078cf00cf352', 356),\n",
       " ('b874a616affcb766bb0e7a4f2a0803f0', 357),\n",
       " ('40f86d376acde0d9862ce7493745bdae', 357),\n",
       " ('db1318d32df7428076e03513ebf762bb', 361),\n",
       " ('80687062449ff7454e2c8926be56f643', 367),\n",
       " ('8a1a67964c0cbea29fc9801b5c42c553', 367),\n",
       " ('f7e1cb7b67e7b154d9dca7d12879d7b0', 372),\n",
       " ('5aabfc58470d01bb2362795a44a2603b', 375),\n",
       " ('b844978933b7ae43e32ce775494821eb', 376),\n",
       " ('397c63db1c7b507d23abff3f8bb0fa18', 376),\n",
       " ('1950e9aa6ad878bc2a330880f77ae5a1', 377),\n",
       " ('c16781c4321948227193214b68477a5c', 377),\n",
       " ('d09f796f2b0aa11dffc88badd9806119', 378),\n",
       " ('50591a7061fb340d875723f38e00cc3b', 380),\n",
       " ('c3e9d9ebe5f2900190bef9342c440bd9', 383),\n",
       " ('bc0ddf03c667c5edb17982be481ef360', 384),\n",
       " ('1a8d67dbb446bdc4298cc0be56932a38', 385),\n",
       " ('83e9823eb4868ca162fd3b7adff70096', 387),\n",
       " ('5fc2ffdd3d24ab503edd9a271dc379bd', 388),\n",
       " ('dd4989789d310581024ae2b9203d5439', 388),\n",
       " ('ce3d8977aae5986601232aa58d15282a', 389),\n",
       " ('6f80666437feea42f295cdc0f1eb4df9', 389),\n",
       " ('0eeac4ecff259dc515be795e1a76019a', 390),\n",
       " ('a6027a4ba71b61a55ea598379c9d508c', 391),\n",
       " ('481c5c92d55717167e01821144a54635', 393),\n",
       " ('121fffad1eb6f7dff228b8a71b6aec72', 397),\n",
       " ('10bc951c2eb4a2f05fa773bdaace4e3b', 397),\n",
       " ('3f8dc381ccfe9d5cc88b75970262715b', 400),\n",
       " ('d8a3c897c506be7de91d8f892f14f934', 401),\n",
       " ('96e7b1bc8d52e18caf0af34fec2e9bcb', 402),\n",
       " ('3cc9a44380296d93e68b71a27643c25f', 413)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import preprocess2 as pp\n",
    "# a képek betöltése és előfeldolgozása\n",
    "csv_data, author_stat = pp.csv_load()\n",
    "# a 10 legtöbb képpel rendelkező alkotót kiválogatjuk\n",
    "authors_to_select = author_stat[-100:]\n",
    "authors_to_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 images in the result\n"
     ]
    }
   ],
   "source": [
    "csv_data = pp.csv_select(csv_data, authors_to_select)\n",
    "# az útvonalnak az összes képet tartalmazó könyvtárra kell mutatnia, mert különben\n",
    "# nem fog tudni belőle elég képet kiolvasni\n",
    "train_images, labels = pp.load_images(csv_data, \"train_sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 1 2 0 4]\n",
      "[[ 0.  0.  0.  1.  0.]\n",
      " [ 0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "# adatok megfelelő formátumra hozása a keras számára\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "encoder.fit(labels)\n",
    "\n",
    "encoded_l = encoder.transform(labels)\n",
    "print(encoded_l)\n",
    "\n",
    "labels_onehot = to_categorical(encoded_l)\n",
    "print(labels_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TrainingHistory(Callback):\n",
    "    # Tanulási folyamat elején létrehozunk egy-egy üres listát a kinyerni kívánt metrikák tárolása céljából.\n",
    "    def on_train_begin(self, logs={}):\n",
    "        # Hiba mértéke a tanító adatokon.\n",
    "        self.losses = []\n",
    "        # Hiba mértéke a validációs adatokon.\n",
    "        self.valid_losses = []\n",
    "        # A modell jóságát, pontosságát mérő mutatószám a tanító adatokon. \n",
    "        self.accs = []\n",
    "        # A modell jóságát, pontosságát mérő mutatószám a validációs adatokon. \n",
    "        self.valid_accs = []\n",
    "        # A tanítási fázisok sorszámozása.\n",
    "        self.epoch = 0\n",
    "    \n",
    "    # Minden egyes tanítási fázis végén mentsük el, hogy hogyan teljesít aktuálisan a háló. \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % 1 == 0:\n",
    "            self.losses.append(logs.get('loss'))\n",
    "            self.valid_losses.append(logs.get('val_loss'))\n",
    "            self.accs.append(logs.get('acc'))\n",
    "            self.valid_accs.append(logs.get('val_acc'))\n",
    "            self.epoch += 1\n",
    "            \n",
    "history = TrainingHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##########################################################\n",
    "# error esetére, elvileg nem okoz gondot 'jó' esetben sem\n",
    "import tensorflow as tf\n",
    "tf.python.control_flow_ops = tf\n",
    "##########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "im_input = Input(shape=(256,256,3))\n",
    "\n",
    "# előtanított modell betöltése, a fully-connected rétegek nélkül\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False, input_tensor=im_input)\n",
    "# az utolsó konvolúciós réteg utána egy global average pooling réteget teszünk, ez rögtön \"lapítja\" (flatten) a 2D konvolúciót"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# kinyerjük a stílusjegyeket a cnn köztes rétegegeiből (és max pool cnn kimeneti rétegére)\n",
    "desired_layers = [28, 44, 60, 70, 92, 114, 136, 158, 172, 194]\n",
    "style_layers = [None]*len(desired_layers)\n",
    "\n",
    "for i in range(len(desired_layers)):\n",
    "    style_layers[i] = base_model.layers[desired_layers[i]].output\n",
    "    style_layers[i] = GlobalAveragePooling2D()(style_layers[i])\n",
    "    style_layers[i] = Dense(base_model.layers[desired_layers[i]].output_shape[3], activation='relu')(style_layers[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# egymás mellé tesszük a különböző szintű feature-öket\n",
    "style_output = merge(style_layers, mode='concat', name='style_output')\n",
    "\n",
    "# ezután hozzáadunk két előrecsatolt réteget ReLU aktivációs függvénnyel\n",
    "ff = Dense(2048, activation='relu')(style_output)\n",
    "ff = Dropout(0.5)(ff)\n",
    "ff = Dense(1024, activation='relu')(ff)\n",
    "\n",
    "# és végül egy kimenete lesz a hálónak - a \"binary_crossentropy\" költségfüggvénynek erre van szüksége\n",
    "predictions = Dense(labels_onehot.shape[1], activation='softmax')(ff)\n",
    "# a model létrehozása\n",
    "model = Model(input=base_model.input, output=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# két lépésben fogjuk tanítani a hálót\n",
    "# az első lépésben csak az előrecsatolt rétegeket tanítjuk, a konvolúciós rétegeket befagyasztjuk\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "# lefordítjuk a modelt (fontos, hogy ezt a rétegek befagyasztása után csináljuk\"\n",
    "# mivel két osztályunk van, ezért bináris keresztentrópia költségfüggvényt használunk\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      "4/4 [==============================] - 3s - loss: 1.5287 - acc: 0.5000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd248fdfe10>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, labels_onehot, batch_size=8, nb_epoch=1, validation_split=0.2, callbacks=[history])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Az Inception V3 konvolúciós rétegei:\n",
      "0 input_1\n",
      "1 convolution2d_1\n",
      "2 batchnormalization_1\n",
      "3 convolution2d_2\n",
      "4 batchnormalization_2\n",
      "5 convolution2d_3\n",
      "6 batchnormalization_3\n",
      "7 maxpooling2d_1\n",
      "8 convolution2d_4\n",
      "9 batchnormalization_4\n",
      "10 convolution2d_5\n",
      "11 batchnormalization_5\n",
      "12 maxpooling2d_2\n",
      "13 convolution2d_9\n",
      "14 batchnormalization_9\n",
      "15 convolution2d_7\n",
      "16 convolution2d_10\n",
      "17 batchnormalization_7\n",
      "18 batchnormalization_10\n",
      "19 averagepooling2d_1\n",
      "20 convolution2d_6\n",
      "21 convolution2d_8\n",
      "22 convolution2d_11\n",
      "23 convolution2d_12\n",
      "24 batchnormalization_6\n",
      "25 batchnormalization_8\n",
      "26 batchnormalization_11\n",
      "27 batchnormalization_12\n",
      "28 mixed0\n",
      "29 convolution2d_16\n",
      "30 batchnormalization_16\n",
      "31 convolution2d_14\n",
      "32 convolution2d_17\n",
      "33 batchnormalization_14\n",
      "34 batchnormalization_17\n",
      "35 averagepooling2d_2\n",
      "36 convolution2d_13\n",
      "37 convolution2d_15\n",
      "38 convolution2d_18\n",
      "39 convolution2d_19\n",
      "40 batchnormalization_13\n",
      "41 batchnormalization_15\n",
      "42 batchnormalization_18\n",
      "43 batchnormalization_19\n",
      "44 mixed1\n",
      "45 convolution2d_23\n",
      "46 batchnormalization_23\n",
      "47 convolution2d_21\n",
      "48 convolution2d_24\n",
      "49 batchnormalization_21\n",
      "50 batchnormalization_24\n",
      "51 averagepooling2d_3\n",
      "52 convolution2d_20\n",
      "53 convolution2d_22\n",
      "54 convolution2d_25\n",
      "55 convolution2d_26\n",
      "56 batchnormalization_20\n",
      "57 batchnormalization_22\n",
      "58 batchnormalization_25\n",
      "59 batchnormalization_26\n",
      "60 mixed2\n",
      "61 convolution2d_28\n",
      "62 batchnormalization_28\n",
      "63 convolution2d_29\n",
      "64 batchnormalization_29\n",
      "65 convolution2d_27\n",
      "66 convolution2d_30\n",
      "67 batchnormalization_27\n",
      "68 batchnormalization_30\n",
      "69 maxpooling2d_3\n",
      "70 mixed3\n",
      "71 convolution2d_35\n",
      "72 batchnormalization_35\n",
      "73 convolution2d_36\n",
      "74 batchnormalization_36\n",
      "75 convolution2d_32\n",
      "76 convolution2d_37\n",
      "77 batchnormalization_32\n",
      "78 batchnormalization_37\n",
      "79 convolution2d_33\n",
      "80 convolution2d_38\n",
      "81 batchnormalization_33\n",
      "82 batchnormalization_38\n",
      "83 averagepooling2d_4\n",
      "84 convolution2d_31\n",
      "85 convolution2d_34\n",
      "86 convolution2d_39\n",
      "87 convolution2d_40\n",
      "88 batchnormalization_31\n",
      "89 batchnormalization_34\n",
      "90 batchnormalization_39\n",
      "91 batchnormalization_40\n",
      "92 mixed4\n",
      "93 convolution2d_45\n",
      "94 batchnormalization_45\n",
      "95 convolution2d_46\n",
      "96 batchnormalization_46\n",
      "97 convolution2d_42\n",
      "98 convolution2d_47\n",
      "99 batchnormalization_42\n",
      "100 batchnormalization_47\n",
      "101 convolution2d_43\n",
      "102 convolution2d_48\n",
      "103 batchnormalization_43\n",
      "104 batchnormalization_48\n",
      "105 averagepooling2d_5\n",
      "106 convolution2d_41\n",
      "107 convolution2d_44\n",
      "108 convolution2d_49\n",
      "109 convolution2d_50\n",
      "110 batchnormalization_41\n",
      "111 batchnormalization_44\n",
      "112 batchnormalization_49\n",
      "113 batchnormalization_50\n",
      "114 mixed5\n",
      "115 convolution2d_55\n",
      "116 batchnormalization_55\n",
      "117 convolution2d_56\n",
      "118 batchnormalization_56\n",
      "119 convolution2d_52\n",
      "120 convolution2d_57\n",
      "121 batchnormalization_52\n",
      "122 batchnormalization_57\n",
      "123 convolution2d_53\n",
      "124 convolution2d_58\n",
      "125 batchnormalization_53\n",
      "126 batchnormalization_58\n",
      "127 averagepooling2d_6\n",
      "128 convolution2d_51\n",
      "129 convolution2d_54\n",
      "130 convolution2d_59\n",
      "131 convolution2d_60\n",
      "132 batchnormalization_51\n",
      "133 batchnormalization_54\n",
      "134 batchnormalization_59\n",
      "135 batchnormalization_60\n",
      "136 mixed6\n",
      "137 convolution2d_65\n",
      "138 batchnormalization_65\n",
      "139 convolution2d_66\n",
      "140 batchnormalization_66\n",
      "141 convolution2d_62\n",
      "142 convolution2d_67\n",
      "143 batchnormalization_62\n",
      "144 batchnormalization_67\n",
      "145 convolution2d_63\n",
      "146 convolution2d_68\n",
      "147 batchnormalization_63\n",
      "148 batchnormalization_68\n",
      "149 averagepooling2d_7\n",
      "150 convolution2d_61\n",
      "151 convolution2d_64\n",
      "152 convolution2d_69\n",
      "153 convolution2d_70\n",
      "154 batchnormalization_61\n",
      "155 batchnormalization_64\n",
      "156 batchnormalization_69\n",
      "157 batchnormalization_70\n",
      "158 mixed7\n",
      "159 convolution2d_73\n",
      "160 batchnormalization_73\n",
      "161 convolution2d_74\n",
      "162 batchnormalization_74\n",
      "163 convolution2d_71\n",
      "164 convolution2d_75\n",
      "165 batchnormalization_71\n",
      "166 batchnormalization_75\n",
      "167 convolution2d_72\n",
      "168 convolution2d_76\n",
      "169 batchnormalization_72\n",
      "170 batchnormalization_76\n",
      "171 averagepooling2d_8\n",
      "172 mixed8\n",
      "173 convolution2d_81\n",
      "174 batchnormalization_81\n",
      "175 convolution2d_78\n",
      "176 convolution2d_82\n",
      "177 batchnormalization_78\n",
      "178 batchnormalization_82\n",
      "179 convolution2d_79\n",
      "180 convolution2d_80\n",
      "181 convolution2d_83\n",
      "182 convolution2d_84\n",
      "183 averagepooling2d_9\n",
      "184 convolution2d_77\n",
      "185 batchnormalization_79\n",
      "186 batchnormalization_80\n",
      "187 batchnormalization_83\n",
      "188 batchnormalization_84\n",
      "189 convolution2d_85\n",
      "190 batchnormalization_77\n",
      "191 mixed9_0\n",
      "192 merge_1\n",
      "193 batchnormalization_85\n",
      "194 mixed9\n",
      "195 globalaveragepooling2d_1\n",
      "196 globalaveragepooling2d_2\n",
      "197 globalaveragepooling2d_3\n",
      "198 globalaveragepooling2d_4\n",
      "199 globalaveragepooling2d_5\n",
      "200 globalaveragepooling2d_6\n",
      "201 globalaveragepooling2d_7\n",
      "202 globalaveragepooling2d_8\n",
      "203 globalaveragepooling2d_9\n",
      "204 globalaveragepooling2d_10\n",
      "205 dense_1\n",
      "206 dense_2\n",
      "207 dense_3\n",
      "208 dense_4\n",
      "209 dense_5\n",
      "210 dense_6\n",
      "211 dense_7\n",
      "212 dense_8\n",
      "213 dense_9\n",
      "214 dense_10\n",
      "215 style_output\n",
      "216 dense_11\n",
      "217 dropout_1\n",
      "218 dense_12\n",
      "219 dense_13\n"
     ]
    }
   ],
   "source": [
    "# ehhez először nézzük meg a háló felépítését\n",
    "print(\"Az Inception V3 konvolúciós rétegei:\")\n",
    "for i, layer in enumerate(model.layers):\n",
    "   print(i, layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# majd a hálónak csak az első 172 rétegét fagyasztjuk, a többit pedig engedjük tanulni\n",
    "for layer in model.layers[:172]:\n",
    "   layer.trainable = False\n",
    "for layer in model.layers[172:]:\n",
    "   layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      "4/4 [==============================] - 4s - loss: 0.0898 - acc: 1.0000 - val_loss: 12.5789 - val_acc: 0.0000e+00\n",
      "Tanítás vége.\n"
     ]
    }
   ],
   "source": [
    "# ez után újra le kell fordítanunk a hálót, hogy most már az Inception V3 felsőbb rétegei tanuljanak\n",
    "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# és ismét indítunk egy tanítást, ezúttal nem csak az előrecsatolt rétegek,\n",
    "# hanem az Inception V3 felső rétegei is tovább tanulnak\n",
    "model.fit(train_images, labels_onehot,  batch_size=16, nb_epoch=1, validation_split=0.2, callbacks=[history])\n",
    "print(\"Tanítás vége.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_values = model.predict(np.asarray(train_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'3cc9a44380296d93e68b71a27643c25f': array([ 0.        ,  0.        ,  0.71451682, ...,  0.        ,\n",
      "        0.102036  ,  0.20697585], dtype=float32), 'e1587900e782de448f604b37cde0fdfd': array([ 0.        ,  0.        ,  0.30844185, ...,  0.05654748,\n",
      "        0.        ,  0.38040966], dtype=float32), '8e441c5899bf3d2f3b2c493e62fb92bf': array([ 0.56115144,  0.        ,  1.09738946, ...,  0.021096  ,\n",
      "        0.03279456,  0.65711933], dtype=float32), 'cc47068929413a16aa707faefbdf4b70': array([ 1.11500239,  0.        ,  0.37770706, ...,  0.        ,\n",
      "        0.        ,  0.16324107], dtype=float32), 'c56bcab4b317984013ebef5d3c4b5906': array([ 0.        ,  0.        ,  0.84439641, ...,  0.27395222,\n",
      "        0.        ,  0.15159859], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "style_out = Model(input=base_model.input, output=style_output)\n",
    "styles = style_out.predict(np.asarray(train_images))\n",
    "style_dict = {}\n",
    "for i in range(len(labels)):\n",
    "    if(labels[i] in style_dict):\n",
    "        style_dict[labels[i]] = (style_dict[labels[i]] + styles[i]) * 0.5\n",
    "    else:\n",
    "        style_dict[labels[i]] = styles[i]\n",
    "    \n",
    "print(style_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 1, 2, 0, 1]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_pred = np.zeros(predicted_values.shape, dtype=int)\n",
    "festok = []\n",
    "for i, pred in enumerate(predicted_values):\n",
    "    d = np.argmax(pred)\n",
    "    max_pred[i, d] = 1\n",
    "    festok.append(d)\n",
    "festok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cc47068929413a16aa707faefbdf4b70',\n",
       "       '8e441c5899bf3d2f3b2c493e62fb92bf',\n",
       "       'c56bcab4b317984013ebef5d3c4b5906',\n",
       "       '3cc9a44380296d93e68b71a27643c25f',\n",
       "       '8e441c5899bf3d2f3b2c493e62fb92bf'], \n",
       "      dtype='<U32')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.inverse_transform(festok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ones = np.ones((256,256,3))\n",
    "\n",
    "ones_input = Input(shape =(256,256,3))\n",
    "synth_layer = Convolution2D(3, 256, 256, init='glorot_uniform', weights=None, border_mode='same', subsample=(1, 1), bias=True)(ones_input)\n",
    "#style_loss = style_out(synth_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Deep Dreaming in Keras.\n",
    "\n",
    "Run the script with:\n",
    "```\n",
    "python deep_dream.py path_to_your_base_image.jpg prefix_for_results\n",
    "```\n",
    "e.g.:\n",
    "```\n",
    "python deep_dream.py img/mypic.jpg results/dream\n",
    "```\n",
    "\n",
    "It is preferable to run this script on GPU, for speed.\n",
    "If running on CPU, prefer the TensorFlow backend (much faster).\n",
    "\n",
    "Example results: http://i.imgur.com/FX6ROg9.jpg\n",
    "'''\n",
    "from __future__ import print_function\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "import numpy as np\n",
    "from scipy.misc import imsave\n",
    "from scipy.optimize import fmin_l_bfgs_b\n",
    "import time\n",
    "import argparse\n",
    "\n",
    "from keras.applications import vgg16\n",
    "from keras import backend as K\n",
    "from keras.layers import Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dimensions of the generated picture.\n",
    "img_width = 256\n",
    "img_height = 256\n",
    "\n",
    "# path to the model weights file.\n",
    "weights_path = 'vgg16_weights.h5'\n",
    "\n",
    "# some settings we found interesting\n",
    "saved_settings = {\n",
    "    'bad_trip': {'features': {'block4_conv1': 0.05,\n",
    "                              'block4_conv2': 0.01,\n",
    "                              'block4_conv3': 0.01},\n",
    "                 'continuity': 0.1,\n",
    "                 'dream_l2': 0.8,\n",
    "                 'jitter': 5},\n",
    "    'dreamy': {'features': {'convolution2d_2': 0.05,\n",
    "                            'convolution2d_3': 0.05},\n",
    "               'continuity': 0.1,\n",
    "               'dream_l2': 0.02,\n",
    "               'jitter': 0},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_image():\n",
    "    img = np.random.random((256,256,3))\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = vgg16.preprocess_input(img)\n",
    "    return img\n",
    "\n",
    "# util function to convert a tensor into a valid image\n",
    "def deprocess_image(x):\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "        x = x.reshape((3, img_width, img_height))\n",
    "        x = x.transpose((1, 2, 0))\n",
    "    else:\n",
    "        x = x.reshape((img_width, img_height, 3))\n",
    "    # Remove zero-center by mean pixel\n",
    "    x[:, :, 0] += 103.939\n",
    "    x[:, :, 1] += 116.779\n",
    "    x[:, :, 2] += 123.68\n",
    "    # 'BGR'->'RGB'\n",
    "    x = x[:, :, ::-1]\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x\n",
    "\n",
    "if K.image_dim_ordering() == 'th':\n",
    "    img_size = (3, img_width, img_height)\n",
    "else:\n",
    "    img_size = (img_width, img_height, 3)\n",
    "# this will contain our generated image\n",
    "dream = Input(batch_shape=(1,) + img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n"
     ]
    }
   ],
   "source": [
    "# build the VGG16 network with our placeholder\n",
    "# the model will be loaded with pre-trained ImageNet weights\n",
    "model2 = vgg16.VGG16(input_tensor=dream, weights='imagenet', include_top=False)\n",
    "print('Model loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the settings we will use in this experiment\n",
    "settings = saved_settings['dreamy']\n",
    "\n",
    "\n",
    "# get the symbolic outputs of each \"key\" layer (we gave them unique names).\n",
    "layer_dict = dict([(layer.name, layer) for layer in model.layers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# continuity loss util function\n",
    "def continuity_loss(x):\n",
    "    assert K.ndim(x) == 4\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "        a = K.square(x[:, :, :img_width - 1, :img_height - 1] -\n",
    "                     x[:, :, 1:, :img_height - 1])\n",
    "        b = K.square(x[:, :, :img_width - 1, :img_height - 1] -\n",
    "                     x[:, :, :img_width - 1, 1:])\n",
    "    else:\n",
    "        a = K.square(x[:, :img_width - 1, :img_height-1, :] -\n",
    "                     x[:, 1:, :img_height - 1, :])\n",
    "        b = K.square(x[:, :img_width - 1, :img_height-1, :] -\n",
    "                     x[:, :img_width - 1, 1:, :])\n",
    "    return K.sum(K.pow(a + b, 1.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.layers.convolutional.Convolution2D object at 0x7fd2520285c0>\n",
      "Tensor(\"Squeeze_121:0\", shape=(125, 125, 32), dtype=float32)\n",
      "(None, 125, 125, 32)\n",
      "<keras.layers.convolutional.Convolution2D object at 0x7fd25075d390>\n",
      "Tensor(\"Squeeze_122:0\", shape=(125, 125, 64), dtype=float32)\n",
      "(None, 125, 125, 64)\n"
     ]
    }
   ],
   "source": [
    "# define the loss\n",
    "loss = K.variable(0.)\n",
    "for layer_name in settings['features']:\n",
    "    # add the L2 norm of the features of a layer to the loss\n",
    "    assert layer_name in layer_dict.keys(), 'Layer ' + layer_name + ' not found in model.'\n",
    "    coeff = settings['features'][layer_name]\n",
    "    x = layer_dict[layer_name].output\n",
    "    print(layer_dict[layer_name])\n",
    "    x = x[0,:,:,:]\n",
    "    print(x)\n",
    "    shape = layer_dict[layer_name].output_shape\n",
    "    print(shape)\n",
    "    # we avoid border artifacts by only involving non-border pixels in the loss\n",
    "    loss -= coeff * K.sum(K.square(x[2: shape[1] - 2, 2: shape[2] - 2, :])) / np.prod(shape[1:])\n",
    "\n",
    "# add continuity loss (gives image local coherence, can result in an artful blur)\n",
    "loss += settings['continuity'] * continuity_loss(dream) / np.prod(img_size)\n",
    "# add image L2 norm to loss (prevents pixels from taking very high values, makes image darker)\n",
    "loss += settings['dream_l2'] * K.sum(K.square(dream)) / np.prod(img_size)\n",
    "\n",
    "# feel free to further modify the loss as you see fit, to achieve new effects..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"add_331:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# compute the gradients of the dream wrt the loss\n",
    "grads = K.gradients(loss, dream)\n",
    "print(loss)\n",
    "outputs = [loss]\n",
    "if type(grads) in {list, tuple}:\n",
    "    outputs += grads\n",
    "else:\n",
    "    outputs.append(grads)\n",
    "\n",
    "f_outputs = K.function([dream], outputs)\n",
    "def eval_loss_and_grads(x):\n",
    "    x = x.reshape((1,) + img_size)\n",
    "    print(x)\n",
    "    outs = f_outputs([x])\n",
    "    loss_value = outs[0]\n",
    "    if len(outs[1:]) == 1:\n",
    "        grad_values = outs[1].flatten().astype('float64')\n",
    "    else:\n",
    "        grad_values = np.array(outs[1:]).flatten().astype('float64')\n",
    "    return loss_value, grad_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of iteration 0\n",
      "[[[[-103.66170519 -116.44717959 -123.52004745]\n",
      "   [-103.51080197 -116.44416334 -122.79904106]\n",
      "   [-103.55824657 -115.78824907 -122.7704693 ]\n",
      "   ..., \n",
      "   [-103.49367728 -116.67054468 -123.47167165]\n",
      "   [-103.61399327 -115.87243195 -123.13025461]\n",
      "   [-102.9782557  -115.96227704 -122.77619619]]\n",
      "\n",
      "  [[-103.01159095 -116.39104603 -123.37518834]\n",
      "   [-103.82858565 -115.84573768 -123.46859101]\n",
      "   [-103.28007695 -115.82469597 -123.55114392]\n",
      "   ..., \n",
      "   [-103.28695538 -115.80719137 -123.25847049]\n",
      "   [-103.45643999 -115.89458082 -123.04602775]\n",
      "   [-103.20019628 -116.14888766 -123.30115994]]\n",
      "\n",
      "  [[-103.24851191 -116.56837697 -123.54113148]\n",
      "   [-103.3799732  -116.0481408  -122.94516678]\n",
      "   [-103.799905   -116.50604127 -123.65660377]\n",
      "   ..., \n",
      "   [-103.30758138 -115.98334972 -123.16692325]\n",
      "   [-102.98577493 -115.96931958 -123.62185359]\n",
      "   [-103.10433609 -116.67282719 -123.34295628]]\n",
      "\n",
      "  ..., \n",
      "  [[-103.15535476 -116.71088936 -123.23716906]\n",
      "   [-103.4250752  -116.12548976 -123.02520804]\n",
      "   [-103.21092942 -116.05418043 -122.96244856]\n",
      "   ..., \n",
      "   [-103.87681769 -116.15184862 -123.52668819]\n",
      "   [-103.63098427 -116.09533839 -123.28103946]\n",
      "   [-103.5142914  -116.07402546 -123.22747865]]\n",
      "\n",
      "  [[-103.54307045 -116.66735716 -123.44685725]\n",
      "   [-103.8122449  -116.17634817 -122.77373024]\n",
      "   [-103.91905976 -116.30600636 -123.22265042]\n",
      "   ..., \n",
      "   [-103.93160976 -116.02766174 -123.34646098]\n",
      "   [-103.59800886 -116.31975465 -122.91309309]\n",
      "   [-102.95673329 -116.70951613 -123.19512324]]\n",
      "\n",
      "  [[-103.53705597 -116.39452206 -123.42214968]\n",
      "   [-103.30270755 -116.67885651 -123.54768656]\n",
      "   [-103.49753951 -116.50776279 -122.71020794]\n",
      "   ..., \n",
      "   [-103.47214477 -116.51952592 -123.49135573]\n",
      "   [-103.24905579 -116.16684854 -123.10293854]\n",
      "   [-103.24451878 -116.64467809 -123.22084316]]]]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "You must feed a value for placeholder tensor 'input_1' with dtype float\n\t [[Node: input_1 = Placeholder[dtype=DT_FLOAT, shape=[], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\nCaused by op 'input_1', defined at:\n  File \"/home/kohlmann/anaconda3/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/kohlmann/anaconda3/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/kohlmann/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/kohlmann/anaconda3/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/kohlmann/anaconda3/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/kohlmann/anaconda3/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/kohlmann/anaconda3/lib/python3.5/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/kohlmann/anaconda3/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/kohlmann/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/kohlmann/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/kohlmann/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/kohlmann/anaconda3/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/kohlmann/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/kohlmann/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/kohlmann/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/kohlmann/anaconda3/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/kohlmann/anaconda3/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/kohlmann/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/kohlmann/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/kohlmann/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-7-0fda0cac6e2a>\", line 1, in <module>\n    im_input = Input(shape=(256,256,3))\n  File \"/home/kohlmann/anaconda3/lib/python3.5/site-packages/keras/engine/topology.py\", line 1074, in Input\n    input_tensor=tensor)\n  File \"/home/kohlmann/anaconda3/lib/python3.5/site-packages/keras/engine/topology.py\", line 992, in __init__\n    name=self.name)\n  File \"/home/kohlmann/anaconda3/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\", line 220, in placeholder\n    x = tf.placeholder(dtype, shape=shape, name=name)\n  File \"/home/kohlmann/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py\", line 1274, in placeholder\n    name=name)\n  File \"/home/kohlmann/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1522, in _placeholder\n    name=name)\n  File \"/home/kohlmann/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 703, in apply_op\n    op_def=op_def)\n  File \"/home/kohlmann/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2310, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/kohlmann/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1232, in __init__\n    self._traceback = _extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/home/kohlmann/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    729\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kohlmann/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    711\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 712\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m    713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kohlmann/anaconda3/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kohlmann/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/errors.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    449\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    451\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'input_1' with dtype float\n\t [[Node: input_1 = Placeholder[dtype=DT_FLOAT, shape=[], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-d5fed3dbdb55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;31m# run L-BFGS for 7 steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     x, min_val, info = fmin_l_bfgs_b(evaluator.loss, x.flatten(),\n\u001b[0;32m---> 41\u001b[0;31m                                      fprime=evaluator.grads, maxfun=7)\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Current loss value:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;31m# decode the dream and save it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kohlmann/anaconda3/lib/python3.5/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36mfmin_l_bfgs_b\u001b[0;34m(func, x0, fprime, args, approx_grad, bounds, m, factr, pgtol, epsilon, iprint, maxfun, maxiter, disp, callback, maxls)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     res = _minimize_lbfgsb(fun, x0, args=args, jac=jac, bounds=bounds,\n\u001b[0;32m--> 193\u001b[0;31m                            **opts)\n\u001b[0m\u001b[1;32m    194\u001b[0m     d = {'grad': res['jac'],\n\u001b[1;32m    195\u001b[0m          \u001b[0;34m'task'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'message'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kohlmann/anaconda3/lib/python3.5/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, **unknown_options)\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kohlmann/anaconda3/lib/python3.5/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36mfunc_and_grad\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m             \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kohlmann/anaconda3/lib/python3.5/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*wrapper_args)\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-90-d5fed3dbdb55>\u001b[0m in \u001b[0;36mloss\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mloss_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_loss_and_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-89-de9e757439a1>\u001b[0m in \u001b[0;36meval_loss_and_grads\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mimg_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mloss_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kohlmann/anaconda3/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1088\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1090\u001b[0;31m         \u001b[0mupdated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1091\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kohlmann/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 382\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    383\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kohlmann/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    653\u001b[0m     \u001b[0mmovers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_with_movers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m     results = self._do_run(handle, target_list, unique_fetches,\n\u001b[0;32m--> 655\u001b[0;31m                            feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0;31m# User may have fetched the same tensor multiple times, but we\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kohlmann/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 723\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    724\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/kohlmann/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    741\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 743\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    744\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'input_1' with dtype float\n\t [[Node: input_1 = Placeholder[dtype=DT_FLOAT, shape=[], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\nCaused by op 'input_1', defined at:\n  File \"/home/kohlmann/anaconda3/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/kohlmann/anaconda3/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/kohlmann/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/kohlmann/anaconda3/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/kohlmann/anaconda3/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/kohlmann/anaconda3/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/kohlmann/anaconda3/lib/python3.5/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/kohlmann/anaconda3/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/kohlmann/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/kohlmann/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/kohlmann/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/kohlmann/anaconda3/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/kohlmann/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/kohlmann/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/kohlmann/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/kohlmann/anaconda3/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/kohlmann/anaconda3/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/kohlmann/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/kohlmann/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/kohlmann/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-7-0fda0cac6e2a>\", line 1, in <module>\n    im_input = Input(shape=(256,256,3))\n  File \"/home/kohlmann/anaconda3/lib/python3.5/site-packages/keras/engine/topology.py\", line 1074, in Input\n    input_tensor=tensor)\n  File \"/home/kohlmann/anaconda3/lib/python3.5/site-packages/keras/engine/topology.py\", line 992, in __init__\n    name=self.name)\n  File \"/home/kohlmann/anaconda3/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\", line 220, in placeholder\n    x = tf.placeholder(dtype, shape=shape, name=name)\n  File \"/home/kohlmann/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py\", line 1274, in placeholder\n    name=name)\n  File \"/home/kohlmann/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1522, in _placeholder\n    name=name)\n  File \"/home/kohlmann/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 703, in apply_op\n    op_def=op_def)\n  File \"/home/kohlmann/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2310, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/kohlmann/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1232, in __init__\n    self._traceback = _extract_stack()\n"
     ]
    }
   ],
   "source": [
    "# this Evaluator class makes it possible\n",
    "# to compute loss and gradients in one pass\n",
    "# while retrieving them via two separate functions,\n",
    "# \"loss\" and \"grads\". This is done because scipy.optimize\n",
    "# requires separate functions for loss and gradients,\n",
    "# but computing them separately would be inefficient.\n",
    "class Evaluator(object):\n",
    "    def __init__(self):\n",
    "        self.loss_value = None\n",
    "        self.grad_values = None\n",
    "\n",
    "    def loss(self, x):\n",
    "        assert self.loss_value is None\n",
    "        loss_value, grad_values = eval_loss_and_grads(x)\n",
    "        self.loss_value = loss_value\n",
    "        self.grad_values = grad_values\n",
    "        return self.loss_value\n",
    "\n",
    "    def grads(self, x):\n",
    "        assert self.loss_value is not None\n",
    "        grad_values = np.copy(self.grad_values)\n",
    "        self.loss_value = None\n",
    "        self.grad_values = None\n",
    "        return grad_values\n",
    "\n",
    "evaluator = Evaluator()\n",
    "\n",
    "# run scipy-based optimization (L-BFGS) over the pixels of the generated image\n",
    "# so as to minimize the loss\n",
    "x = preprocess_image()\n",
    "for i in range(5):\n",
    "    print('Start of iteration', i)\n",
    "    start_time = time.time()\n",
    "\n",
    "    # add a random jitter to the initial image. This will be reverted at decoding time\n",
    "    random_jitter = (settings['jitter'] * 2) * (np.random.random(img_size) - 0.5)\n",
    "    x += random_jitter\n",
    "\n",
    "    # run L-BFGS for 7 steps\n",
    "    x, min_val, info = fmin_l_bfgs_b(evaluator.loss, x.flatten(),\n",
    "                                     fprime=evaluator.grads, maxfun=7)\n",
    "    print('Current loss value:', min_val)\n",
    "    # decode the dream and save it\n",
    "    x = x.reshape(img_size)\n",
    "    x -= random_jitter\n",
    "    img = deprocess_image(np.copy(x))\n",
    "    fname = 'resuat_iteration_%d.png' % i\n",
    "    imsave(fname, img)\n",
    "    end_time = time.time()\n",
    "    print('Image saved as', fname)\n",
    "    print('Iteration %d completed in %ds' % (i, end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.inception_v3 import InceptionV3,preprocess_input,decode_predictions\n",
    "from keras.preprocessing import image\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, merge\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "from keras.callbacks import Callback\n",
    "from sklearn import preprocessing\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "import preprocess as ppx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# a képek betöltése és előfeldolgozása\n",
    "image_file_names, data = ppx.csv_load()\n",
    "image_name_dict, images = ppx.load_images(image_file_names, \"/media/bence/121A62041A61E4E7/learn/train_sample\")\n",
    "train_images, train_data = ppx.data_preprocess(images, data, image_name_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 256, 256, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 102  724  373 ...,  706 1256  813]\n",
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "# adatok megfelelő formátumra hozása a keras számára\n",
    "labels = np.array([ls[1] for ls in train_data])\n",
    "\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "encoder.fit(labels)\n",
    "\n",
    "encoded_l = encoder.transform(labels)\n",
    "print(encoded_l)\n",
    "\n",
    "labels_onehot = to_categorical(encoded_l)\n",
    "print(labels_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TrainingHistory(Callback):\n",
    "    # Tanulási folyamat elején létrehozunk egy-egy üres listát a kinyerni kívánt metrikák tárolása céljából.\n",
    "    def on_train_begin(self, logs={}):\n",
    "        # Hiba mértéke a tanító adatokon.\n",
    "        self.losses = []\n",
    "        # Hiba mértéke a validációs adatokon.\n",
    "        self.valid_losses = []\n",
    "        # A modell jóságát, pontosságát mérő mutatószám a tanító adatokon. \n",
    "        self.accs = []\n",
    "        # A modell jóságát, pontosságát mérő mutatószám a validációs adatokon. \n",
    "        self.valid_accs = []\n",
    "        # A tanítási fázisok sorszámozása.\n",
    "        self.epoch = 0\n",
    "    \n",
    "    # Minden egyes tanítási fázis végén mentsük el, hogy hogyan teljesít aktuálisan a háló. \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % 1 == 0:\n",
    "            self.losses.append(logs.get('loss'))\n",
    "            self.valid_losses.append(logs.get('val_loss'))\n",
    "            self.accs.append(logs.get('acc'))\n",
    "            self.valid_accs.append(logs.get('val_acc'))\n",
    "            self.epoch += 1\n",
    "            \n",
    "history = TrainingHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##########################################################\n",
    "# error esetére, elvileg nem okoz gondot 'jó' esetben sem\n",
    "import tensorflow as tf\n",
    "tf.python.control_flow_ops = tf\n",
    "##########################################################\n",
    "\n",
    "# előtanított modell betöltése, a fully-connected rétegek nélkül\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "# az utolsó konvolúciós réteg utána egy global average pooling réteget teszünk, ez rögtön \"lapítja\" (flatten) a 2D konvolúciót\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf\n",
      "tf\n",
      "tf\n",
      "tf\n"
     ]
    }
   ],
   "source": [
    "# kinyerjük a stílusjegyeket a cnn köztes rétegegeiből (és max pool cnn kimeneti rétegére)\n",
    "style1 = base_model.layers[54 ].output\n",
    "style1 = GlobalAveragePooling2D()(style1)\n",
    "style1 = Dense(96, activation='relu')(style1)\n",
    "style2 = base_model.layers[117].output\n",
    "style2 = GlobalAveragePooling2D()(style2)\n",
    "style2 = Dense(160, activation='relu')(style2)\n",
    "style3 = base_model.layers[184].output\n",
    "style3 = GlobalAveragePooling2D()(style3)\n",
    "style3 = Dense(320, activation='relu')(style3)\n",
    "\n",
    "style_final = base_model.output\n",
    "style_final = GlobalAveragePooling2D()(style_final)\n",
    "\n",
    "# egymás mellé tesszük a különböző szintű feature-öket\n",
    "ff = merge([style1, style2, style3, style_final], mode='concat')\n",
    "\n",
    "# ezután hozzáadunk két előrecsatolt réteget ReLU aktivációs függvénnyel\n",
    "ff = Dense(1024, activation='relu')(ff)\n",
    "ff = Dense(1024, activation='relu')(ff)\n",
    "ff = Dense(1024, activation='relu')(ff)\n",
    "\n",
    "# és végül egy kimenete lesz a hálónak - a \"binary_crossentropy\" költségfüggvénynek erre van szüksége\n",
    "predictions = Dense(labels_onehot.shape[1], activation='softmax')(ff)\n",
    "# a model létrehozása\n",
    "model = Model(input=base_model.input, output=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# két lépésben fogjuk tanítani a hálót\n",
    "# az első lépésben csak az előrecsatolt rétegeket tanítjuk, a konvolúciós rétegeket befagyasztjuk\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "# lefordítjuk a modelt (fontos, hogy ezt a rétegek befagyasztása után csináljuk\"\n",
    "# mivel két osztályunk van, ezért bináris keresztentrópia költségfüggvényt használunk\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6400 samples, validate on 1600 samples\n",
      "Epoch 1/50\n",
      "6400/6400 [==============================] - 200s - loss: 6.8438 - acc: 0.0127 - val_loss: 7.3308 - val_acc: 0.0131\n",
      "Epoch 2/50\n",
      "6400/6400 [==============================] - 196s - loss: 6.3816 - acc: 0.0236 - val_loss: 7.0970 - val_acc: 0.0194\n",
      "Epoch 3/50\n",
      "6400/6400 [==============================] - 197s - loss: 6.1089 - acc: 0.0303 - val_loss: 7.1723 - val_acc: 0.0238\n",
      "Epoch 4/50\n",
      "6400/6400 [==============================] - 196s - loss: 5.8878 - acc: 0.0416 - val_loss: 7.2343 - val_acc: 0.0300\n",
      "Epoch 5/50\n",
      "6400/6400 [==============================] - 196s - loss: 5.7486 - acc: 0.0519 - val_loss: 7.1477 - val_acc: 0.0325\n",
      "Epoch 6/50\n",
      "6400/6400 [==============================] - 196s - loss: 5.5625 - acc: 0.0633 - val_loss: 7.4856 - val_acc: 0.0375\n",
      "Epoch 7/50\n",
      "6400/6400 [==============================] - 197s - loss: 5.4162 - acc: 0.0766 - val_loss: 7.4649 - val_acc: 0.0456\n",
      "Epoch 8/50\n",
      "6400/6400 [==============================] - 197s - loss: 5.3136 - acc: 0.0844 - val_loss: 7.3875 - val_acc: 0.0512\n",
      "Epoch 9/50\n",
      "6400/6400 [==============================] - 197s - loss: 5.1904 - acc: 0.0931 - val_loss: 7.3083 - val_acc: 0.0531\n",
      "Epoch 10/50\n",
      "6400/6400 [==============================] - 196s - loss: 5.0814 - acc: 0.0955 - val_loss: 7.2852 - val_acc: 0.0512\n",
      "Epoch 11/50\n",
      "6400/6400 [==============================] - 196s - loss: 4.9622 - acc: 0.1073 - val_loss: 7.6438 - val_acc: 0.0450\n",
      "Epoch 12/50\n",
      "6400/6400 [==============================] - 197s - loss: 4.8905 - acc: 0.1156 - val_loss: 7.4032 - val_acc: 0.0469\n",
      "Epoch 13/50\n",
      "6400/6400 [==============================] - 197s - loss: 4.7688 - acc: 0.1209 - val_loss: 7.7403 - val_acc: 0.0631\n",
      "Epoch 14/50\n",
      "6400/6400 [==============================] - 197s - loss: 4.7036 - acc: 0.1288 - val_loss: 7.8185 - val_acc: 0.0681\n",
      "Epoch 15/50\n",
      "6400/6400 [==============================] - 197s - loss: 4.6175 - acc: 0.1314 - val_loss: 7.6941 - val_acc: 0.0606\n",
      "Epoch 16/50\n",
      "6400/6400 [==============================] - 197s - loss: 4.5743 - acc: 0.1433 - val_loss: 7.6444 - val_acc: 0.0663\n",
      "Epoch 17/50\n",
      "6400/6400 [==============================] - 197s - loss: 4.4682 - acc: 0.1527 - val_loss: 7.8221 - val_acc: 0.0700\n",
      "Epoch 18/50\n",
      "6400/6400 [==============================] - 197s - loss: 4.3941 - acc: 0.1577 - val_loss: 7.8567 - val_acc: 0.0644\n",
      "Epoch 19/50\n",
      "6400/6400 [==============================] - 197s - loss: 4.3373 - acc: 0.1602 - val_loss: 7.8446 - val_acc: 0.0563\n",
      "Epoch 20/50\n",
      "6400/6400 [==============================] - 197s - loss: 4.2594 - acc: 0.1766 - val_loss: 7.8128 - val_acc: 0.0625\n",
      "Epoch 21/50\n",
      "6400/6400 [==============================] - 197s - loss: 4.2175 - acc: 0.1731 - val_loss: 7.7844 - val_acc: 0.0638\n",
      "Epoch 22/50\n",
      "6400/6400 [==============================] - 197s - loss: 4.1560 - acc: 0.1842 - val_loss: 8.0629 - val_acc: 0.0619\n",
      "Epoch 23/50\n",
      "6400/6400 [==============================] - 197s - loss: 4.1421 - acc: 0.1917 - val_loss: 8.1517 - val_acc: 0.0669\n",
      "Epoch 24/50\n",
      "6400/6400 [==============================] - 197s - loss: 4.0769 - acc: 0.1989 - val_loss: 7.8759 - val_acc: 0.0650\n",
      "Epoch 25/50\n",
      "6400/6400 [==============================] - 197s - loss: 3.9902 - acc: 0.2063 - val_loss: 8.0075 - val_acc: 0.0606\n",
      "Epoch 26/50\n",
      "6400/6400 [==============================] - 197s - loss: 4.0241 - acc: 0.2042 - val_loss: 8.0922 - val_acc: 0.0575\n",
      "Epoch 27/50\n",
      "6400/6400 [==============================] - 197s - loss: 3.9111 - acc: 0.2189 - val_loss: 8.3467 - val_acc: 0.0556\n",
      "Epoch 28/50\n",
      "6400/6400 [==============================] - 197s - loss: 3.8589 - acc: 0.2255 - val_loss: 8.0794 - val_acc: 0.0612\n",
      "Epoch 29/50\n",
      "6400/6400 [==============================] - 197s - loss: 3.8629 - acc: 0.2269 - val_loss: 7.9718 - val_acc: 0.0663\n",
      "Epoch 30/50\n",
      "6400/6400 [==============================] - 197s - loss: 3.8010 - acc: 0.2328 - val_loss: 8.3854 - val_acc: 0.0750\n",
      "Epoch 31/50\n",
      "6400/6400 [==============================] - 197s - loss: 3.7733 - acc: 0.2389 - val_loss: 8.1132 - val_acc: 0.0725\n",
      "Epoch 32/50\n",
      "6400/6400 [==============================] - 197s - loss: 3.7825 - acc: 0.2366 - val_loss: 8.1655 - val_acc: 0.0650\n",
      "Epoch 33/50\n",
      "6400/6400 [==============================] - 197s - loss: 3.6951 - acc: 0.2503 - val_loss: 8.5086 - val_acc: 0.0688\n",
      "Epoch 34/50\n",
      "6400/6400 [==============================] - 197s - loss: 3.6429 - acc: 0.2587 - val_loss: 8.3846 - val_acc: 0.0638\n",
      "Epoch 35/50\n",
      "6400/6400 [==============================] - 197s - loss: 3.5991 - acc: 0.2692 - val_loss: 8.7258 - val_acc: 0.0675\n",
      "Epoch 36/50\n",
      "6400/6400 [==============================] - 197s - loss: 3.5929 - acc: 0.2656 - val_loss: 8.5075 - val_acc: 0.0638\n",
      "Epoch 37/50\n",
      "6400/6400 [==============================] - 197s - loss: 3.5794 - acc: 0.2687 - val_loss: 8.5786 - val_acc: 0.0644\n",
      "Epoch 38/50\n",
      "6400/6400 [==============================] - 197s - loss: 3.5870 - acc: 0.2641 - val_loss: 8.5299 - val_acc: 0.0762\n",
      "Epoch 39/50\n",
      "6400/6400 [==============================] - 197s - loss: 3.4992 - acc: 0.2880 - val_loss: 8.9409 - val_acc: 0.0619\n",
      "Epoch 40/50\n",
      "6400/6400 [==============================] - 197s - loss: 3.5024 - acc: 0.2916 - val_loss: 8.6543 - val_acc: 0.0544\n",
      "Epoch 41/50\n",
      "6400/6400 [==============================] - 197s - loss: 3.4995 - acc: 0.2811 - val_loss: 8.4806 - val_acc: 0.0606\n",
      "Epoch 42/50\n",
      "6400/6400 [==============================] - 197s - loss: 3.4771 - acc: 0.2838 - val_loss: 8.3373 - val_acc: 0.0631\n",
      "Epoch 43/50\n",
      "6400/6400 [==============================] - 197s - loss: 3.4545 - acc: 0.2895 - val_loss: 8.8471 - val_acc: 0.0681\n",
      "Epoch 44/50\n",
      "6400/6400 [==============================] - 197s - loss: 3.4078 - acc: 0.3072 - val_loss: 8.7746 - val_acc: 0.0712\n",
      "Epoch 45/50\n",
      "6400/6400 [==============================] - 197s - loss: 3.4523 - acc: 0.2928 - val_loss: 9.0073 - val_acc: 0.0675\n",
      "Epoch 46/50\n",
      "6400/6400 [==============================] - 197s - loss: 3.3726 - acc: 0.3048 - val_loss: 8.5715 - val_acc: 0.0650\n",
      "Epoch 47/50\n",
      "6400/6400 [==============================] - 197s - loss: 3.3697 - acc: 0.3019 - val_loss: 8.8116 - val_acc: 0.0638\n",
      "Epoch 48/50\n",
      "6400/6400 [==============================] - 197s - loss: 3.3800 - acc: 0.3119 - val_loss: 8.7747 - val_acc: 0.0569\n",
      "Epoch 49/50\n",
      "6400/6400 [==============================] - 197s - loss: 3.3324 - acc: 0.3120 - val_loss: 8.9115 - val_acc: 0.0581\n",
      "Epoch 50/50\n",
      "6400/6400 [==============================] - 197s - loss: 3.3619 - acc: 0.3058 - val_loss: 8.8292 - val_acc: 0.0669\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0d2e225e48>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, labels_onehot, batch_size=8, nb_epoch=50, validation_split=0.2, callbacks=[history])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Az Inception V3 konvolúciós rétegei:\n",
      "0 input_1\n",
      "1 convolution2d_1\n",
      "2 batchnormalization_1\n",
      "3 convolution2d_2\n",
      "4 batchnormalization_2\n",
      "5 convolution2d_3\n",
      "6 batchnormalization_3\n",
      "7 maxpooling2d_1\n",
      "8 convolution2d_4\n",
      "9 batchnormalization_4\n",
      "10 convolution2d_5\n",
      "11 batchnormalization_5\n",
      "12 maxpooling2d_2\n",
      "13 convolution2d_9\n",
      "14 batchnormalization_9\n",
      "15 convolution2d_7\n",
      "16 convolution2d_10\n",
      "17 batchnormalization_7\n",
      "18 batchnormalization_10\n",
      "19 averagepooling2d_1\n",
      "20 convolution2d_6\n",
      "21 convolution2d_8\n",
      "22 convolution2d_11\n",
      "23 convolution2d_12\n",
      "24 batchnormalization_6\n",
      "25 batchnormalization_8\n",
      "26 batchnormalization_11\n",
      "27 batchnormalization_12\n",
      "28 mixed0\n",
      "29 convolution2d_16\n",
      "30 batchnormalization_16\n",
      "31 convolution2d_14\n",
      "32 convolution2d_17\n",
      "33 batchnormalization_14\n",
      "34 batchnormalization_17\n",
      "35 averagepooling2d_2\n",
      "36 convolution2d_13\n",
      "37 convolution2d_15\n",
      "38 convolution2d_18\n",
      "39 convolution2d_19\n",
      "40 batchnormalization_13\n",
      "41 batchnormalization_15\n",
      "42 batchnormalization_18\n",
      "43 batchnormalization_19\n",
      "44 mixed1\n",
      "45 convolution2d_23\n",
      "46 batchnormalization_23\n",
      "47 convolution2d_21\n",
      "48 convolution2d_24\n",
      "49 batchnormalization_21\n",
      "50 batchnormalization_24\n",
      "51 averagepooling2d_3\n",
      "52 convolution2d_20\n",
      "53 convolution2d_22\n",
      "54 convolution2d_25\n",
      "55 convolution2d_26\n",
      "56 batchnormalization_20\n",
      "57 batchnormalization_22\n",
      "58 batchnormalization_25\n",
      "59 batchnormalization_26\n",
      "60 mixed2\n",
      "61 convolution2d_28\n",
      "62 batchnormalization_28\n",
      "63 convolution2d_29\n",
      "64 batchnormalization_29\n",
      "65 convolution2d_27\n",
      "66 convolution2d_30\n",
      "67 batchnormalization_27\n",
      "68 batchnormalization_30\n",
      "69 maxpooling2d_3\n",
      "70 mixed3\n",
      "71 convolution2d_35\n",
      "72 batchnormalization_35\n",
      "73 convolution2d_36\n",
      "74 batchnormalization_36\n",
      "75 convolution2d_32\n",
      "76 convolution2d_37\n",
      "77 batchnormalization_32\n",
      "78 batchnormalization_37\n",
      "79 convolution2d_33\n",
      "80 convolution2d_38\n",
      "81 batchnormalization_33\n",
      "82 batchnormalization_38\n",
      "83 averagepooling2d_4\n",
      "84 convolution2d_31\n",
      "85 convolution2d_34\n",
      "86 convolution2d_39\n",
      "87 convolution2d_40\n",
      "88 batchnormalization_31\n",
      "89 batchnormalization_34\n",
      "90 batchnormalization_39\n",
      "91 batchnormalization_40\n",
      "92 mixed4\n",
      "93 convolution2d_45\n",
      "94 batchnormalization_45\n",
      "95 convolution2d_46\n",
      "96 batchnormalization_46\n",
      "97 convolution2d_42\n",
      "98 convolution2d_47\n",
      "99 batchnormalization_42\n",
      "100 batchnormalization_47\n",
      "101 convolution2d_43\n",
      "102 convolution2d_48\n",
      "103 batchnormalization_43\n",
      "104 batchnormalization_48\n",
      "105 averagepooling2d_5\n",
      "106 convolution2d_41\n",
      "107 convolution2d_44\n",
      "108 convolution2d_49\n",
      "109 convolution2d_50\n",
      "110 batchnormalization_41\n",
      "111 batchnormalization_44\n",
      "112 batchnormalization_49\n",
      "113 batchnormalization_50\n",
      "114 mixed5\n",
      "115 convolution2d_55\n",
      "116 batchnormalization_55\n",
      "117 convolution2d_56\n",
      "118 batchnormalization_56\n",
      "119 convolution2d_52\n",
      "120 convolution2d_57\n",
      "121 batchnormalization_52\n",
      "122 batchnormalization_57\n",
      "123 convolution2d_53\n",
      "124 convolution2d_58\n",
      "125 batchnormalization_53\n",
      "126 batchnormalization_58\n",
      "127 averagepooling2d_6\n",
      "128 convolution2d_51\n",
      "129 convolution2d_54\n",
      "130 convolution2d_59\n",
      "131 convolution2d_60\n",
      "132 batchnormalization_51\n",
      "133 batchnormalization_54\n",
      "134 batchnormalization_59\n",
      "135 batchnormalization_60\n",
      "136 mixed6\n",
      "137 convolution2d_65\n",
      "138 batchnormalization_65\n",
      "139 convolution2d_66\n",
      "140 batchnormalization_66\n",
      "141 convolution2d_62\n",
      "142 convolution2d_67\n",
      "143 batchnormalization_62\n",
      "144 batchnormalization_67\n",
      "145 convolution2d_63\n",
      "146 convolution2d_68\n",
      "147 batchnormalization_63\n",
      "148 batchnormalization_68\n",
      "149 averagepooling2d_7\n",
      "150 convolution2d_61\n",
      "151 convolution2d_64\n",
      "152 convolution2d_69\n",
      "153 convolution2d_70\n",
      "154 batchnormalization_61\n",
      "155 batchnormalization_64\n",
      "156 batchnormalization_69\n",
      "157 batchnormalization_70\n",
      "158 mixed7\n",
      "159 convolution2d_73\n",
      "160 batchnormalization_73\n",
      "161 convolution2d_74\n",
      "162 batchnormalization_74\n",
      "163 convolution2d_71\n",
      "164 convolution2d_75\n",
      "165 batchnormalization_71\n",
      "166 batchnormalization_75\n",
      "167 convolution2d_72\n",
      "168 convolution2d_76\n",
      "169 batchnormalization_72\n",
      "170 batchnormalization_76\n",
      "171 averagepooling2d_8\n",
      "172 mixed8\n",
      "173 convolution2d_81\n",
      "174 batchnormalization_81\n",
      "175 convolution2d_78\n",
      "176 convolution2d_82\n",
      "177 batchnormalization_78\n",
      "178 batchnormalization_82\n",
      "179 convolution2d_79\n",
      "180 convolution2d_80\n",
      "181 convolution2d_83\n",
      "182 convolution2d_84\n",
      "183 averagepooling2d_9\n",
      "184 convolution2d_77\n",
      "185 batchnormalization_79\n",
      "186 batchnormalization_80\n",
      "187 batchnormalization_83\n",
      "188 batchnormalization_84\n",
      "189 convolution2d_85\n",
      "190 batchnormalization_77\n",
      "191 mixed9_0\n",
      "192 merge_1\n",
      "193 batchnormalization_85\n",
      "194 mixed9\n",
      "195 convolution2d_90\n",
      "196 batchnormalization_90\n",
      "197 convolution2d_87\n",
      "198 convolution2d_91\n",
      "199 batchnormalization_87\n",
      "200 batchnormalization_91\n",
      "201 convolution2d_88\n",
      "202 convolution2d_89\n",
      "203 convolution2d_92\n",
      "204 convolution2d_93\n",
      "205 averagepooling2d_10\n",
      "206 convolution2d_86\n",
      "207 batchnormalization_88\n",
      "208 batchnormalization_89\n",
      "209 batchnormalization_92\n",
      "210 batchnormalization_93\n",
      "211 convolution2d_94\n",
      "212 batchnormalization_86\n",
      "213 mixed9_1\n",
      "214 merge_2\n",
      "215 batchnormalization_94\n",
      "216 mixed10\n"
     ]
    }
   ],
   "source": [
    "# ehhez először nézzük meg a háló felépítését\n",
    "print(\"Az Inception V3 konvolúciós rétegei:\")\n",
    "for i, layer in enumerate(base_model.layers):\n",
    "   print(i, layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# majd a hálónak csak az első 172 rétegét fagyasztjuk, a többit pedig engedjük tanulni\n",
    "for layer in model.layers[:172]:\n",
    "   layer.trainable = False\n",
    "for layer in model.layers[172:]:\n",
    "   layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6400 samples, validate on 1600 samples\n",
      "Epoch 1/100\n",
      "6400/6400 [==============================] - 194s - loss: 1.7358 - acc: 0.5666 - val_loss: 8.6953 - val_acc: 0.1006\n",
      "Epoch 2/100\n",
      "6400/6400 [==============================] - 190s - loss: 1.6791 - acc: 0.5784 - val_loss: 8.8507 - val_acc: 0.1062\n",
      "Epoch 3/100\n",
      "6400/6400 [==============================] - 190s - loss: 1.6430 - acc: 0.5909 - val_loss: 8.8472 - val_acc: 0.0938\n",
      "Epoch 4/100\n",
      "6400/6400 [==============================] - 190s - loss: 1.5926 - acc: 0.5983 - val_loss: 8.9638 - val_acc: 0.1006\n",
      "Epoch 5/100\n",
      "6400/6400 [==============================] - 190s - loss: 1.5584 - acc: 0.6045 - val_loss: 8.9511 - val_acc: 0.1006\n",
      "Epoch 6/100\n",
      "6400/6400 [==============================] - 190s - loss: 1.5367 - acc: 0.6134 - val_loss: 9.0559 - val_acc: 0.0938\n",
      "Epoch 7/100\n",
      "6400/6400 [==============================] - 190s - loss: 1.4951 - acc: 0.6236 - val_loss: 8.9893 - val_acc: 0.0969\n",
      "Epoch 8/100\n",
      "6400/6400 [==============================] - 190s - loss: 1.4322 - acc: 0.6348 - val_loss: 9.0272 - val_acc: 0.0988\n",
      "Epoch 9/100\n",
      "6400/6400 [==============================] - 190s - loss: 1.4203 - acc: 0.6306 - val_loss: 9.0893 - val_acc: 0.0994\n",
      "Epoch 10/100\n",
      "6400/6400 [==============================] - 190s - loss: 1.3913 - acc: 0.6420 - val_loss: 9.1202 - val_acc: 0.1013\n",
      "Epoch 11/100\n",
      "6400/6400 [==============================] - 190s - loss: 1.3747 - acc: 0.6433 - val_loss: 9.1476 - val_acc: 0.0994\n",
      "Epoch 12/100\n",
      "6400/6400 [==============================] - 190s - loss: 1.3330 - acc: 0.6564 - val_loss: 9.2038 - val_acc: 0.0919\n",
      "Epoch 13/100\n",
      "6400/6400 [==============================] - 190s - loss: 1.3058 - acc: 0.6648 - val_loss: 9.2226 - val_acc: 0.0938\n",
      "Epoch 14/100\n",
      "6400/6400 [==============================] - 190s - loss: 1.2744 - acc: 0.6652 - val_loss: 9.2173 - val_acc: 0.0950\n",
      "Epoch 15/100\n",
      "6400/6400 [==============================] - 190s - loss: 1.2406 - acc: 0.6794 - val_loss: 9.3187 - val_acc: 0.0969\n",
      "Epoch 16/100\n",
      "6400/6400 [==============================] - 190s - loss: 1.2350 - acc: 0.6847 - val_loss: 9.2543 - val_acc: 0.0969\n",
      "Epoch 17/100\n",
      "6400/6400 [==============================] - 190s - loss: 1.2170 - acc: 0.6837 - val_loss: 9.3220 - val_acc: 0.0963\n",
      "Epoch 18/100\n",
      "6400/6400 [==============================] - 190s - loss: 1.1962 - acc: 0.6859 - val_loss: 9.3794 - val_acc: 0.1000\n",
      "Epoch 19/100\n",
      "6400/6400 [==============================] - 190s - loss: 1.1732 - acc: 0.6938 - val_loss: 9.3913 - val_acc: 0.1062\n",
      "Epoch 20/100\n",
      "6400/6400 [==============================] - 190s - loss: 1.1422 - acc: 0.7039 - val_loss: 9.3024 - val_acc: 0.0950\n",
      "Epoch 21/100\n",
      "6400/6400 [==============================] - 190s - loss: 1.1527 - acc: 0.6967 - val_loss: 9.2824 - val_acc: 0.0963\n",
      "Epoch 22/100\n",
      "6400/6400 [==============================] - 190s - loss: 1.0788 - acc: 0.7186 - val_loss: 9.4552 - val_acc: 0.1031\n",
      "Epoch 23/100\n",
      "6400/6400 [==============================] - 190s - loss: 1.0481 - acc: 0.7239 - val_loss: 9.4610 - val_acc: 0.0950\n",
      "Epoch 24/100\n",
      "6400/6400 [==============================] - 190s - loss: 1.0539 - acc: 0.7242 - val_loss: 9.4578 - val_acc: 0.1025\n",
      "Epoch 25/100\n",
      "6400/6400 [==============================] - 190s - loss: 1.0329 - acc: 0.7267 - val_loss: 9.5247 - val_acc: 0.1013\n",
      "Epoch 26/100\n",
      "6400/6400 [==============================] - 190s - loss: 1.0110 - acc: 0.7362 - val_loss: 9.4369 - val_acc: 0.0988\n",
      "Epoch 27/100\n",
      "6400/6400 [==============================] - 190s - loss: 0.9989 - acc: 0.7367 - val_loss: 9.4862 - val_acc: 0.1062\n",
      "Epoch 28/100\n",
      "6400/6400 [==============================] - 190s - loss: 0.9621 - acc: 0.7458 - val_loss: 9.5306 - val_acc: 0.0994\n",
      "Epoch 29/100\n",
      "6400/6400 [==============================] - 190s - loss: 0.9561 - acc: 0.7453 - val_loss: 9.6721 - val_acc: 0.0975\n",
      "Epoch 30/100\n",
      "6400/6400 [==============================] - 190s - loss: 0.9331 - acc: 0.7534 - val_loss: 9.6902 - val_acc: 0.0950\n",
      "Epoch 31/100\n",
      "6400/6400 [==============================] - 190s - loss: 0.9186 - acc: 0.7561 - val_loss: 9.6537 - val_acc: 0.0925\n",
      "Epoch 32/100\n",
      "6400/6400 [==============================] - 190s - loss: 0.9147 - acc: 0.7566 - val_loss: 9.6362 - val_acc: 0.0963\n",
      "Epoch 33/100\n",
      "6400/6400 [==============================] - 190s - loss: 0.8989 - acc: 0.7622 - val_loss: 9.6878 - val_acc: 0.0994\n",
      "Epoch 34/100\n",
      "6400/6400 [==============================] - 190s - loss: 0.8692 - acc: 0.7719 - val_loss: 9.6788 - val_acc: 0.0950\n",
      "Epoch 35/100\n",
      "6400/6400 [==============================] - 190s - loss: 0.8521 - acc: 0.7700 - val_loss: 9.7935 - val_acc: 0.0900\n",
      "Epoch 36/100\n",
      "6400/6400 [==============================] - 190s - loss: 0.8247 - acc: 0.7809 - val_loss: 9.8084 - val_acc: 0.1013\n",
      "Epoch 37/100\n",
      "6400/6400 [==============================] - 190s - loss: 0.8146 - acc: 0.7827 - val_loss: 9.7135 - val_acc: 0.0944\n",
      "Epoch 38/100\n",
      "6400/6400 [==============================] - 190s - loss: 0.7972 - acc: 0.7878 - val_loss: 9.8130 - val_acc: 0.0981\n",
      "Epoch 39/100\n",
      "6400/6400 [==============================] - 190s - loss: 0.7929 - acc: 0.7903 - val_loss: 9.8392 - val_acc: 0.0969\n",
      "Epoch 40/100\n",
      "6400/6400 [==============================] - 190s - loss: 0.7786 - acc: 0.7967 - val_loss: 9.7826 - val_acc: 0.0931\n",
      "Epoch 41/100\n",
      "6400/6400 [==============================] - 190s - loss: 0.7783 - acc: 0.7959 - val_loss: 9.8242 - val_acc: 0.0969\n",
      "Epoch 42/100\n",
      "6400/6400 [==============================] - 190s - loss: 0.7581 - acc: 0.8045 - val_loss: 9.8896 - val_acc: 0.1044\n",
      "Epoch 43/100\n",
      "6400/6400 [==============================] - 190s - loss: 0.7338 - acc: 0.8025 - val_loss: 9.9159 - val_acc: 0.1031\n",
      "Epoch 44/100\n",
      "6400/6400 [==============================] - 190s - loss: 0.7318 - acc: 0.8102 - val_loss: 9.9099 - val_acc: 0.0994\n",
      "Epoch 45/100\n",
      "6400/6400 [==============================] - 190s - loss: 0.7219 - acc: 0.8075 - val_loss: 9.9315 - val_acc: 0.0975\n",
      "Epoch 46/100\n",
      "6400/6400 [==============================] - 190s - loss: 0.7107 - acc: 0.8100 - val_loss: 9.9308 - val_acc: 0.1000\n",
      "Epoch 47/100\n",
      "6400/6400 [==============================] - 190s - loss: 0.7039 - acc: 0.8159 - val_loss: 9.9051 - val_acc: 0.0956\n",
      "Epoch 48/100\n",
      "6400/6400 [==============================] - 190s - loss: 0.6756 - acc: 0.8197 - val_loss: 9.9302 - val_acc: 0.0975\n",
      "Epoch 49/100\n",
      "6400/6400 [==============================] - 190s - loss: 0.6443 - acc: 0.8263 - val_loss: 9.9373 - val_acc: 0.0925\n",
      "Epoch 50/100\n",
      "6400/6400 [==============================] - 190s - loss: 0.6607 - acc: 0.8203 - val_loss: 9.9730 - val_acc: 0.0919\n",
      "Epoch 51/100\n",
      "6400/6400 [==============================] - 190s - loss: 0.6685 - acc: 0.8238 - val_loss: 9.9869 - val_acc: 0.0969\n",
      "Epoch 52/100\n",
      "6400/6400 [==============================] - 190s - loss: 0.6125 - acc: 0.8350 - val_loss: 9.9937 - val_acc: 0.0919\n",
      "Epoch 53/100\n",
      "6400/6400 [==============================] - 190s - loss: 0.6299 - acc: 0.8297 - val_loss: 9.9556 - val_acc: 0.0975\n",
      "Epoch 54/100\n",
      "6400/6400 [==============================] - 190s - loss: 0.6366 - acc: 0.8336 - val_loss: 9.9380 - val_acc: 0.0969\n",
      "Epoch 55/100\n",
      "6400/6400 [==============================] - 190s - loss: 0.5900 - acc: 0.8400 - val_loss: 9.9920 - val_acc: 0.0956\n",
      "Epoch 56/100\n",
      "6400/6400 [==============================] - 190s - loss: 0.6105 - acc: 0.8378 - val_loss: 9.9279 - val_acc: 0.0981\n",
      "Epoch 57/100\n",
      "6400/6400 [==============================] - 190s - loss: 0.5827 - acc: 0.8475 - val_loss: 9.9336 - val_acc: 0.0938\n",
      "Epoch 58/100\n",
      "6400/6400 [==============================] - 190s - loss: 0.5711 - acc: 0.8478 - val_loss: 10.0509 - val_acc: 0.0956\n",
      "Epoch 59/100\n",
      "6400/6400 [==============================] - 190s - loss: 0.5398 - acc: 0.8575 - val_loss: 10.1043 - val_acc: 0.0956\n",
      "Epoch 60/100\n",
      "6400/6400 [==============================] - 190s - loss: 0.5427 - acc: 0.8555 - val_loss: 10.0986 - val_acc: 0.0988\n",
      "Epoch 61/100\n",
      "6400/6400 [==============================] - 190s - loss: 0.5545 - acc: 0.8547 - val_loss: 10.0723 - val_acc: 0.0956\n",
      "Epoch 62/100\n",
      "6400/6400 [==============================] - 190s - loss: 0.5338 - acc: 0.8619 - val_loss: 10.0586 - val_acc: 0.1000\n",
      "Epoch 63/100\n",
      "6400/6400 [==============================] - 190s - loss: 0.5352 - acc: 0.8592 - val_loss: 10.0354 - val_acc: 0.0925\n",
      "Epoch 64/100\n",
      "6400/6400 [==============================] - 190s - loss: 0.5080 - acc: 0.8628 - val_loss: 10.1901 - val_acc: 0.1037\n",
      "Epoch 65/100\n",
      "6400/6400 [==============================] - 190s - loss: 0.5091 - acc: 0.8652 - val_loss: 10.0920 - val_acc: 0.1006\n",
      "Epoch 66/100\n",
      "6400/6400 [==============================] - 190s - loss: 0.5155 - acc: 0.8647 - val_loss: 10.1334 - val_acc: 0.0994\n",
      "Epoch 67/100\n",
      "6400/6400 [==============================] - 190s - loss: 0.5003 - acc: 0.8687 - val_loss: 10.1573 - val_acc: 0.1025\n",
      "Epoch 68/100\n",
      "6400/6400 [==============================] - 190s - loss: 0.5056 - acc: 0.8659 - val_loss: 10.1893 - val_acc: 0.1025\n",
      "Epoch 69/100\n",
      "6400/6400 [==============================] - 190s - loss: 0.4927 - acc: 0.8680 - val_loss: 10.1407 - val_acc: 0.0988\n",
      "Epoch 70/100\n",
      "6400/6400 [==============================] - 190s - loss: 0.4935 - acc: 0.8725 - val_loss: 10.2500 - val_acc: 0.0981\n",
      "Epoch 71/100\n",
      "6400/6400 [==============================] - 190s - loss: 0.4632 - acc: 0.8822 - val_loss: 10.2254 - val_acc: 0.0969\n",
      "Epoch 72/100\n",
      "6400/6400 [==============================] - 190s - loss: 0.4736 - acc: 0.8753 - val_loss: 10.2476 - val_acc: 0.0975\n",
      "Epoch 73/100\n",
      "6400/6400 [==============================] - 190s - loss: 0.4552 - acc: 0.8789 - val_loss: 10.2926 - val_acc: 0.1031\n",
      "Epoch 74/100\n",
      "6400/6400 [==============================] - 190s - loss: 0.4321 - acc: 0.8861 - val_loss: 10.2383 - val_acc: 0.0944\n",
      "Epoch 75/100\n",
      "6400/6400 [==============================] - 190s - loss: 0.4310 - acc: 0.8863 - val_loss: 10.3649 - val_acc: 0.1000\n",
      "Epoch 76/100\n",
      "6400/6400 [==============================] - 190s - loss: 0.4259 - acc: 0.8912 - val_loss: 10.2803 - val_acc: 0.0938\n",
      "Epoch 77/100\n",
      "6400/6400 [==============================] - 190s - loss: 0.4298 - acc: 0.8872 - val_loss: 10.2665 - val_acc: 0.1025\n",
      "Epoch 78/100\n",
      "6400/6400 [==============================] - 190s - loss: 0.4433 - acc: 0.8844 - val_loss: 10.3240 - val_acc: 0.0994\n",
      "Epoch 79/100\n",
      "6400/6400 [==============================] - 190s - loss: 0.4283 - acc: 0.8908 - val_loss: 10.2007 - val_acc: 0.1006\n",
      "Epoch 80/100\n",
      "6400/6400 [==============================] - 190s - loss: 0.4345 - acc: 0.8872 - val_loss: 10.2571 - val_acc: 0.1044\n",
      "Epoch 81/100\n",
      "6400/6400 [==============================] - 190s - loss: 0.3963 - acc: 0.8897 - val_loss: 10.2866 - val_acc: 0.0963\n",
      "Epoch 82/100\n",
      "6400/6400 [==============================] - 190s - loss: 0.3982 - acc: 0.8956 - val_loss: 10.2389 - val_acc: 0.0975\n",
      "Epoch 83/100\n",
      "6400/6400 [==============================] - 190s - loss: 0.3941 - acc: 0.8975 - val_loss: 10.3300 - val_acc: 0.1044\n",
      "Epoch 84/100\n",
      "6400/6400 [==============================] - 190s - loss: 0.3852 - acc: 0.8947 - val_loss: 10.3326 - val_acc: 0.1050\n",
      "Epoch 85/100\n",
      "6400/6400 [==============================] - 190s - loss: 0.3723 - acc: 0.8994 - val_loss: 10.3667 - val_acc: 0.1031\n",
      "Epoch 86/100\n",
      "6400/6400 [==============================] - 190s - loss: 0.3533 - acc: 0.9083 - val_loss: 10.3047 - val_acc: 0.0988\n",
      "Epoch 87/100\n",
      "6400/6400 [==============================] - 190s - loss: 0.3617 - acc: 0.9025 - val_loss: 10.4103 - val_acc: 0.0981\n",
      "Epoch 88/100\n",
      "2864/6400 [============>.................] - ETA: 87s - loss: 0.3790 - acc: 0.9054"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-23a122941df5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# és ismét indítunk egy tanítást, ezúttal nem csak az előrecsatolt rétegek,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# hanem az Inception V3 felső rétegei is tovább tanulnak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_onehot\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tanítás vége.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight)\u001b[0m\n\u001b[1;32m   1104\u001b[0m                               \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m                               callback_metrics=callback_metrics)\n\u001b[0m\u001b[1;32m   1107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics)\u001b[0m\n\u001b[1;32m    822\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    825\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1011\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m         \u001b[0mupdated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1014\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 382\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    383\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    653\u001b[0m     \u001b[0mmovers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_with_movers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m     results = self._do_run(handle, target_list, unique_fetches,\n\u001b[0;32m--> 655\u001b[0;31m                            feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0;31m# User may have fetched the same tensor multiple times, but we\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 723\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    724\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    728\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    710\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m    711\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 712\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m    713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ez után újra le kell fordítanunk a hálót, hogy most már az Inception V3 felsőbb rétegei tanuljanak\n",
    "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# és ismét indítunk egy tanítást, ezúttal nem csak az előrecsatolt rétegek,\n",
    "# hanem az Inception V3 felső rétegei is tovább tanulnak\n",
    "model.fit(train_images, labels_onehot,  batch_size=16, nb_epoch=100, validation_split=0.2, callbacks=[history])\n",
    "print(\"Tanítás vége.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted_values = model.predict(np.asarray(train_images)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 7, 4, 13, 9, 8, 2, 1, 12, 5, 6, 12, 1, 3]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_pred = np.zeros(predicted_values.shape, dtype=int)\n",
    "festok = []\n",
    "for i, pred in enumerate(predicted_values):\n",
    "    d = np.argmax(pred)\n",
    "    max_pred[i, d] = 1\n",
    "    festok.append(d)\n",
    "festok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['5b6a7be5ffc6a27b91bd3210ffa2e088',\n",
       "       'cc47068929413a16aa707faefbdf4b70',\n",
       "       '69904cf890070e9593a566394d5dece4',\n",
       "       'f44205b1eb2de981de766e0688f8cbac',\n",
       "       'da9ab2081b197129eeb91477d239be00',\n",
       "       'd500fe452aef7a6f90de16197a9670bf',\n",
       "       '485d901dc4df30b128bf01cb6e229767',\n",
       "       '3f93b217bd0dbf874f973958f1eb6df4',\n",
       "       'f14a3a6cc3112c9e92bc6c33c88eb264',\n",
       "       '8e441c5899bf3d2f3b2c493e62fb92bf',\n",
       "       'c56bcab4b317984013ebef5d3c4b5906',\n",
       "       'f14a3a6cc3112c9e92bc6c33c88eb264',\n",
       "       '3f93b217bd0dbf874f973958f1eb6df4',\n",
       "       '5b6a7be5ffc6a27b91bd3210ffa2e088'], \n",
       "      dtype='<U32')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.inverse_transform(festok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'out' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-f5b6436ec341>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# vissza kéne alakítani valahogy...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mecovered_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mohc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactive_features_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msorted_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mohc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_indices_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'out' is not defined"
     ]
    }
   ],
   "source": [
    "# vissza kéne alakítani valahogy...\n",
    "ecovered_X = np.array([ohc.active_features_[col] for col in out.sorted_indices().indices])\\\n",
    ".reshape(n_samples, n_features) - ohc.feature_indices_[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.inception_v3 import InceptionV3,preprocess_input,decode_predictions\n",
    "from keras.preprocessing import image\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, merge, Dropout\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "from keras.callbacks import Callback\n",
    "from sklearn import preprocessing\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('342d7068656b00878b23e1031a3ddf50', 165),\n",
       " ('358474690052f63f9107c823b7a61686', 165),\n",
       " ('db85b84c1c01fa143b9294f00f7acbeb', 167),\n",
       " ('30134467c49a3350f74b4311506f8386', 171),\n",
       " ('795985c5c0e7c704a354a487bdffeef5', 171),\n",
       " ('a087f33967e659c63924aa07c89b948f', 172),\n",
       " ('24ed88087b0ffeb763e89a197a5cde0d', 172),\n",
       " ('3a320926ef941d53716127548523450c', 172),\n",
       " ('ed9cf03b71a8a71d41ecb4e8406a0877', 172),\n",
       " ('a7b6670e2d23f415998849a8fdedae18', 174),\n",
       " ('8b1800319323ab9b0ce2e0b11b3f4772', 175),\n",
       " ('3b4ee6d6140803ebef405983f23ffcc1', 176),\n",
       " ('56221362cba30b7e0c96111cc38c5fcd', 176),\n",
       " ('79f6b47483600c140c91e901f746a368', 176),\n",
       " ('83518d02afc5754dd9e79985f56c3355', 178),\n",
       " ('9c948f31fc16aca442cc91e7fe05fb95', 179),\n",
       " ('b31c8ec49c09506f17ec3c0c04fce567', 179),\n",
       " ('062244b785e58518f2f189329633c59e', 181),\n",
       " ('63e73f693e541f53d98ed6c93d03ef40', 185),\n",
       " ('39c465a1d078121873a31807ce9dc2ed', 185),\n",
       " ('ea2beb11e25ec317263983dbdd6de81e', 186),\n",
       " ('1d6d112c140cb6d1d763a7ca73f2eec0', 187),\n",
       " ('74a1dad53214d04514269a188f16683a', 187),\n",
       " ('2cd87bc71a43270dc7ce0917f6f6d980', 188),\n",
       " ('7b5a9186df853ff921c211145ca5ab59', 189),\n",
       " ('489c7bf979f6a993869fdc0ae7e4ae34', 192),\n",
       " ('dcb1d130c7640aefc60890d0e90d472d', 195),\n",
       " ('ede635e53e1b4a905bbea74de30371cf', 195),\n",
       " ('fbaf536ad899a31e80be9ff101b119cc', 197),\n",
       " ('861c29e13205420326f7443ea77de5c9', 200),\n",
       " ('c56bcab4b317984013ebef5d3c4b5906', 200),\n",
       " ('de42ef05d5901837bbe974fdb3c30ba5', 202),\n",
       " ('4b0465826ffd6db797ea6f3a5898df79', 205),\n",
       " ('82665201c4108381d854740ddcb86e67', 205),\n",
       " ('bfb541e54ad5c7320e8f80e2a2163e93', 206),\n",
       " ('1e8267251976e6f3b771b00f32c5798b', 206),\n",
       " ('aceaa52f487dd19129857232b2eeb3d5', 212),\n",
       " ('5e560e9b2ae0c20cfc57b308742bc677', 213),\n",
       " ('5ae394770a82dac7cea5d95ef6482a11', 214),\n",
       " ('b64b426fa2b080ad94a2e1c7f423413c', 214),\n",
       " ('45f4183820ce1fa775f8a27d3120aad6', 215),\n",
       " ('bc58ed3c3e7750f9644953020a39e867', 220),\n",
       " ('ccb8b07e7e3d837b2cd08d3edaf009cd', 220),\n",
       " ('4a30943bf6dd5da55d12ccd14aaff0d8', 229),\n",
       " ('68cbc428edbcf480cbbb9a0e66e7046d', 232),\n",
       " ('9649a0013a798a8367d2c493e37468ec', 245),\n",
       " ('7b016984b86b58f83977299591cf4e38', 246),\n",
       " ('e1587900e782de448f604b37cde0fdfd', 256),\n",
       " ('147b0f64f4c2848bc0ad7bc1cdf74afe', 258),\n",
       " ('1468ab18764365ded902fc726aec2c89', 258),\n",
       " ('129349585c3d1f312535b6619fc36bf7', 267),\n",
       " ('8e441c5899bf3d2f3b2c493e62fb92bf', 268),\n",
       " ('c9380d13360b37f21cfd174d92a7247e', 268),\n",
       " ('c8041306a183cbaf39ff8cd707c9cc7f', 278),\n",
       " ('6460e3ba02dfa3b57ebf5d3d0823aa47', 286),\n",
       " ('dc589f213ba7bd398714ac2796b7c0ab', 291),\n",
       " ('3937af6d364e2f24d1cce16fe3916536', 291),\n",
       " ('62b4406512c45730d2c7c40f5e3d0d12', 294),\n",
       " ('31dbc08b8d0a3196c5484c0c068b2bcc', 294),\n",
       " ('49bb8d79587c2172c6cd04dd705fd891', 297),\n",
       " ('3edc6a404b8c67b7dad1405d52228c96', 297),\n",
       " ('8cdd41002b7b5c5d112865054a7fe13e', 298),\n",
       " ('cc47068929413a16aa707faefbdf4b70', 304),\n",
       " ('54e7b38b5c91716bd3ad99a0ab740a18', 304),\n",
       " ('bd14ef3c1a25cf0c5368ccd92a3c5f04', 304),\n",
       " ('e60882af79cababb03ddfa980a75448c', 305),\n",
       " ('c31b03be3da5810b44ea4782d2f3b8a0', 320),\n",
       " ('512fb34e01bd21a92e7ec1380577c985', 321),\n",
       " ('b36edf57ed623e40e433565053f5f6ca', 345),\n",
       " ('234c8d1df0b49b512791078cf00cf352', 356),\n",
       " ('b874a616affcb766bb0e7a4f2a0803f0', 357),\n",
       " ('40f86d376acde0d9862ce7493745bdae', 357),\n",
       " ('db1318d32df7428076e03513ebf762bb', 361),\n",
       " ('8a1a67964c0cbea29fc9801b5c42c553', 367),\n",
       " ('80687062449ff7454e2c8926be56f643', 367),\n",
       " ('f7e1cb7b67e7b154d9dca7d12879d7b0', 372),\n",
       " ('5aabfc58470d01bb2362795a44a2603b', 375),\n",
       " ('b844978933b7ae43e32ce775494821eb', 376),\n",
       " ('397c63db1c7b507d23abff3f8bb0fa18', 376),\n",
       " ('1950e9aa6ad878bc2a330880f77ae5a1', 377),\n",
       " ('c16781c4321948227193214b68477a5c', 377),\n",
       " ('d09f796f2b0aa11dffc88badd9806119', 378),\n",
       " ('50591a7061fb340d875723f38e00cc3b', 380),\n",
       " ('c3e9d9ebe5f2900190bef9342c440bd9', 383),\n",
       " ('bc0ddf03c667c5edb17982be481ef360', 384),\n",
       " ('1a8d67dbb446bdc4298cc0be56932a38', 385),\n",
       " ('83e9823eb4868ca162fd3b7adff70096', 387),\n",
       " ('dd4989789d310581024ae2b9203d5439', 388),\n",
       " ('5fc2ffdd3d24ab503edd9a271dc379bd', 388),\n",
       " ('6f80666437feea42f295cdc0f1eb4df9', 389),\n",
       " ('ce3d8977aae5986601232aa58d15282a', 389),\n",
       " ('0eeac4ecff259dc515be795e1a76019a', 390),\n",
       " ('a6027a4ba71b61a55ea598379c9d508c', 391),\n",
       " ('481c5c92d55717167e01821144a54635', 393),\n",
       " ('10bc951c2eb4a2f05fa773bdaace4e3b', 397),\n",
       " ('121fffad1eb6f7dff228b8a71b6aec72', 397),\n",
       " ('3f8dc381ccfe9d5cc88b75970262715b', 400),\n",
       " ('d8a3c897c506be7de91d8f892f14f934', 401),\n",
       " ('96e7b1bc8d52e18caf0af34fec2e9bcb', 402),\n",
       " ('3cc9a44380296d93e68b71a27643c25f', 413)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import preprocess2 as pp\n",
    "# a képek betöltése és előfeldolgozása\n",
    "csv_data, author_stat = pp.csv_load()\n",
    "# a 10 legtöbb képpel rendelkező alkotót kiválogatjuk\n",
    "authors_to_select = author_stat[-100:]\n",
    "authors_to_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 images loaded\n",
      "4000 images loaded\n",
      "6000 images loaded\n",
      "8000 images loaded\n",
      "10000 images loaded\n",
      "12000 images loaded\n",
      "14000 images loaded\n",
      "16000 images loaded\n",
      "18000 images loaded\n",
      "20000 images loaded\n",
      "22000 images loaded\n",
      "24000 images loaded\n",
      "26000 images loaded\n",
      "27348 images in the result\n"
     ]
    }
   ],
   "source": [
    "csv_data = pp.csv_select(csv_data, authors_to_select)\n",
    "# az útvonalnak az összes képet tartalmazó könyvtárra kell mutatnia, mert különben\n",
    "# nem fog tudni belőle elég képet kiolvasni\n",
    "train_images, labels = pp.load_images(csv_data, \"/media/bence/121A62041A61E4E7/learn/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23 42 71 ..., 58 23 95]\n",
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "# adatok megfelelő formátumra hozása a keras számára\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "encoder.fit(labels)\n",
    "\n",
    "encoded_l = encoder.transform(labels)\n",
    "print(encoded_l)\n",
    "\n",
    "labels_onehot = to_categorical(encoded_l)\n",
    "print(labels_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TrainingHistory(Callback):\n",
    "    # Tanulási folyamat elején létrehozunk egy-egy üres listát a kinyerni kívánt metrikák tárolása céljából.\n",
    "    def on_train_begin(self, logs={}):\n",
    "        # Hiba mértéke a tanító adatokon.\n",
    "        self.losses = []\n",
    "        # Hiba mértéke a validációs adatokon.\n",
    "        self.valid_losses = []\n",
    "        # A modell jóságát, pontosságát mérő mutatószám a tanító adatokon. \n",
    "        self.accs = []\n",
    "        # A modell jóságát, pontosságát mérő mutatószám a validációs adatokon. \n",
    "        self.valid_accs = []\n",
    "        # A tanítási fázisok sorszámozása.\n",
    "        self.epoch = 0\n",
    "    \n",
    "    # Minden egyes tanítási fázis végén mentsük el, hogy hogyan teljesít aktuálisan a háló. \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % 1 == 0:\n",
    "            self.losses.append(logs.get('loss'))\n",
    "            self.valid_losses.append(logs.get('val_loss'))\n",
    "            self.accs.append(logs.get('acc'))\n",
    "            self.valid_accs.append(logs.get('val_acc'))\n",
    "            self.epoch += 1\n",
    "            \n",
    "history = TrainingHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##########################################################\n",
    "# error esetére, elvileg nem okoz gondot 'jó' esetben sem\n",
    "import tensorflow as tf\n",
    "tf.python.control_flow_ops = tf\n",
    "##########################################################\n",
    "\n",
    "# előtanított modell betöltése, a fully-connected rétegek nélkül\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "# az utolsó konvolúciós réteg utána egy global average pooling réteget teszünk, ez rögtön \"lapítja\" (flatten) a 2D konvolúciót\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf\n",
      "tf\n",
      "tf\n"
     ]
    }
   ],
   "source": [
    "# kinyerjük a stílusjegyeket a cnn köztes rétegegeiből (és max pool cnn kimeneti rétegére)\n",
    "style1 = base_model.layers[54].output\n",
    "style1 = GlobalAveragePooling2D()(style1)\n",
    "style1 = Dense(96, activation='relu')(style1)\n",
    "style2 = base_model.layers[117].output\n",
    "style2 = GlobalAveragePooling2D()(style2)\n",
    "style2 = Dense(160, activation='relu')(style2)\n",
    "style3 = base_model.layers[184].output\n",
    "style3 = GlobalAveragePooling2D()(style3)\n",
    "style3 = Dense(320, activation='relu')(style3)\n",
    "\n",
    "# egymás mellé tesszük a különböző szintű feature-öket\n",
    "ff = merge([style1, style2, style3], mode='concat')\n",
    "\n",
    "# ezután hozzáadunk két előrecsatolt réteget ReLU aktivációs függvénnyel\n",
    "ff = Dense(2048, activation='relu')(ff)\n",
    "ff = Dropout(0.5)(ff)\n",
    "ff = Dense(1024, activation='relu')(ff)\n",
    "\n",
    "# és végül egy kimenete lesz a hálónak - a \"binary_crossentropy\" költségfüggvénynek erre van szüksége\n",
    "predictions = Dense(labels_onehot.shape[1], activation='softmax')(ff)\n",
    "# a model létrehozása\n",
    "model = Model(input=base_model.input, output=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# két lépésben fogjuk tanítani a hálót\n",
    "# az első lépésben csak az előrecsatolt rétegeket tanítjuk, a konvolúciós rétegeket befagyasztjuk\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "# lefordítjuk a modelt (fontos, hogy ezt a rétegek befagyasztása után csináljuk\"\n",
    "# mivel két osztályunk van, ezért bináris keresztentrópia költségfüggvényt használunk\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21878 samples, validate on 5470 samples\n",
      "Epoch 1/50\n",
      "21878/21878 [==============================] - 576s - loss: 3.7353 - acc: 0.1198 - val_loss: 3.6202 - val_acc: 0.2245\n",
      "Epoch 2/50\n",
      "21878/21878 [==============================] - 572s - loss: 3.1318 - acc: 0.2322 - val_loss: 3.3232 - val_acc: 0.2934\n",
      "Epoch 3/50\n",
      "21878/21878 [==============================] - 574s - loss: 2.8861 - acc: 0.2836 - val_loss: 3.1690 - val_acc: 0.3302\n",
      "Epoch 4/50\n",
      "21878/21878 [==============================] - 574s - loss: 2.7382 - acc: 0.3189 - val_loss: 3.1057 - val_acc: 0.3581\n",
      "Epoch 5/50\n",
      "21878/21878 [==============================] - 574s - loss: 2.6271 - acc: 0.3420 - val_loss: 3.0163 - val_acc: 0.3817\n",
      "Epoch 6/50\n",
      "21878/21878 [==============================] - 574s - loss: 2.5438 - acc: 0.3573 - val_loss: 2.9128 - val_acc: 0.3832\n",
      "Epoch 7/50\n",
      "21878/21878 [==============================] - 574s - loss: 2.4903 - acc: 0.3736 - val_loss: 2.8350 - val_acc: 0.3978\n",
      "Epoch 8/50\n",
      "21878/21878 [==============================] - 574s - loss: 2.4388 - acc: 0.3876 - val_loss: 3.0780 - val_acc: 0.3947\n",
      "Epoch 9/50\n",
      "21878/21878 [==============================] - 573s - loss: 2.3871 - acc: 0.3930 - val_loss: 2.8708 - val_acc: 0.4219\n",
      "Epoch 10/50\n",
      "21878/21878 [==============================] - 574s - loss: 2.3725 - acc: 0.3961 - val_loss: 2.8845 - val_acc: 0.4221\n",
      "Epoch 11/50\n",
      "21878/21878 [==============================] - 574s - loss: 2.3134 - acc: 0.4110 - val_loss: 2.8010 - val_acc: 0.4274\n",
      "Epoch 12/50\n",
      "21878/21878 [==============================] - 576s - loss: 2.2892 - acc: 0.4199 - val_loss: 2.8922 - val_acc: 0.4230\n",
      "Epoch 13/50\n",
      "21878/21878 [==============================] - 575s - loss: 2.2645 - acc: 0.4164 - val_loss: 2.9248 - val_acc: 0.4216\n",
      "Epoch 14/50\n",
      "21878/21878 [==============================] - 576s - loss: 2.2541 - acc: 0.4272 - val_loss: 2.8415 - val_acc: 0.4239\n",
      "Epoch 15/50\n",
      "21878/21878 [==============================] - 575s - loss: 2.2437 - acc: 0.4272 - val_loss: 2.8272 - val_acc: 0.4280\n",
      "Epoch 16/50\n",
      "21878/21878 [==============================] - 575s - loss: 2.2259 - acc: 0.4386 - val_loss: 2.8893 - val_acc: 0.4346\n",
      "Epoch 17/50\n",
      "21878/21878 [==============================] - 575s - loss: 2.2064 - acc: 0.4373 - val_loss: 2.8962 - val_acc: 0.4289\n",
      "Epoch 18/50\n",
      "21878/21878 [==============================] - 575s - loss: 2.1949 - acc: 0.4388 - val_loss: 2.8357 - val_acc: 0.4291\n",
      "Epoch 19/50\n",
      "21878/21878 [==============================] - 575s - loss: 2.1925 - acc: 0.4429 - val_loss: 2.8449 - val_acc: 0.4218\n",
      "Epoch 20/50\n",
      "21878/21878 [==============================] - 575s - loss: 2.2011 - acc: 0.4360 - val_loss: 2.9132 - val_acc: 0.4349\n",
      "Epoch 21/50\n",
      "21878/21878 [==============================] - 575s - loss: 2.1946 - acc: 0.4441 - val_loss: 2.8954 - val_acc: 0.4377\n",
      "Epoch 22/50\n",
      "21878/21878 [==============================] - 575s - loss: 2.1518 - acc: 0.4525 - val_loss: 2.9072 - val_acc: 0.4351\n",
      "Epoch 23/50\n",
      "21878/21878 [==============================] - 575s - loss: 2.1498 - acc: 0.4522 - val_loss: 2.8717 - val_acc: 0.4395\n",
      "Epoch 24/50\n",
      "21878/21878 [==============================] - 575s - loss: 2.1601 - acc: 0.4531 - val_loss: 2.9056 - val_acc: 0.4303\n",
      "Epoch 25/50\n",
      "21878/21878 [==============================] - 575s - loss: 2.1352 - acc: 0.4599 - val_loss: 2.9731 - val_acc: 0.4263\n",
      "Epoch 26/50\n",
      "21878/21878 [==============================] - 575s - loss: 2.1613 - acc: 0.4564 - val_loss: 2.9604 - val_acc: 0.4393\n",
      "Epoch 27/50\n",
      "21878/21878 [==============================] - 575s - loss: 2.1653 - acc: 0.4521 - val_loss: 2.9356 - val_acc: 0.4444\n",
      "Epoch 28/50\n",
      "21878/21878 [==============================] - 576s - loss: 2.1485 - acc: 0.4587 - val_loss: 2.9112 - val_acc: 0.4479\n",
      "Epoch 29/50\n",
      "21878/21878 [==============================] - 575s - loss: 2.1528 - acc: 0.4573 - val_loss: 2.8966 - val_acc: 0.4346\n",
      "Epoch 30/50\n",
      "21878/21878 [==============================] - 575s - loss: 2.1339 - acc: 0.4574 - val_loss: 2.9381 - val_acc: 0.4420\n",
      "Epoch 31/50\n",
      "21878/21878 [==============================] - 575s - loss: 2.1489 - acc: 0.4601 - val_loss: 3.1187 - val_acc: 0.4360\n",
      "Epoch 32/50\n",
      "21878/21878 [==============================] - 575s - loss: 2.1374 - acc: 0.4603 - val_loss: 3.0260 - val_acc: 0.4362\n",
      "Epoch 33/50\n",
      "21878/21878 [==============================] - 575s - loss: 2.1403 - acc: 0.4624 - val_loss: 3.0086 - val_acc: 0.4296\n",
      "Epoch 34/50\n",
      "21878/21878 [==============================] - 575s - loss: 2.1468 - acc: 0.4602 - val_loss: 2.9960 - val_acc: 0.4380\n",
      "Epoch 35/50\n",
      "21878/21878 [==============================] - 575s - loss: 2.1689 - acc: 0.4568 - val_loss: 3.0197 - val_acc: 0.4402\n",
      "Epoch 36/50\n",
      "21878/21878 [==============================] - 575s - loss: 2.1357 - acc: 0.4620 - val_loss: 2.9180 - val_acc: 0.4367\n",
      "Epoch 37/50\n",
      "21878/21878 [==============================] - 575s - loss: 2.1457 - acc: 0.4606 - val_loss: 2.9555 - val_acc: 0.4252\n",
      "Epoch 38/50\n",
      "21878/21878 [==============================] - 575s - loss: 2.1333 - acc: 0.4639 - val_loss: 3.0601 - val_acc: 0.4344\n",
      "Epoch 39/50\n",
      "12448/21878 [================>.............] - ETA: 202s - loss: 2.1304 - acc: 0.4688"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-5ed737b9385d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_onehot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight)\u001b[0m\n\u001b[1;32m   1104\u001b[0m                               \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m                               callback_metrics=callback_metrics)\n\u001b[0m\u001b[1;32m   1107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics)\u001b[0m\n\u001b[1;32m    822\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    825\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1011\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m         \u001b[0mupdated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1014\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 382\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    383\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    653\u001b[0m     \u001b[0mmovers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_with_movers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m     results = self._do_run(handle, target_list, unique_fetches,\n\u001b[0;32m--> 655\u001b[0;31m                            feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0;31m# User may have fetched the same tensor multiple times, but we\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 723\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    724\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    728\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    710\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m    711\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 712\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m    713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(train_images, labels_onehot, batch_size=8, nb_epoch=50, validation_split=0.2, callbacks=[history])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ehhez először nézzük meg a háló felépítését\n",
    "print(\"Az Inception V3 konvolúciós rétegei:\")\n",
    "for i, layer in enumerate(base_model.layers):\n",
    "   print(i, layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# majd a hálónak csak az első 172 rétegét fagyasztjuk, a többit pedig engedjük tanulni\n",
    "for layer in model.layers[:172]:\n",
    "   layer.trainable = False\n",
    "for layer in model.layers[172:]:\n",
    "   layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21878 samples, validate on 5470 samples\n",
      "Epoch 1/100\n",
      " 8208/21878 [==========>...................] - ETA: 258s - loss: 1.7744 - acc: 0.5367"
     ]
    }
   ],
   "source": [
    "# ez után újra le kell fordítanunk a hálót, hogy most már az Inception V3 felsőbb rétegei tanuljanak\n",
    "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# és ismét indítunk egy tanítást, ezúttal nem csak az előrecsatolt rétegek,\n",
    "# hanem az Inception V3 felső rétegei is tovább tanulnak\n",
    "model.fit(train_images, labels_onehot,  batch_size=16, nb_epoch=100, validation_split=0.2, callbacks=[history])\n",
    "print(\"Tanítás vége.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted_values = model.predict(np.asarray(train_images)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_pred = np.zeros(predicted_values.shape, dtype=int)\n",
    "festok = []\n",
    "for i, pred in enumerate(predicted_values):\n",
    "    d = np.argmax(pred)\n",
    "    max_pred[i, d] = 1\n",
    "    festok.append(d)\n",
    "festok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encoder.inverse_transform(festok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# vissza kéne alakítani valahogy...\n",
    "ecovered_X = np.array([ohc.active_features_[col] for col in out.sorted_indices().indices])\\\n",
    ".reshape(n_samples, n_features) - ohc.feature_indices_[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
